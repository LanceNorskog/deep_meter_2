{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6ffyQDaP4ot",
        "colab_type": "code",
        "outputId": "dc2a3405-f7b4-40b8-cac9-e57c5cc0851d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "!pip install numpy==1.16.1\n",
        "#!pip install keras==2.1.2\n",
        "\n",
        "from __future__ import print_function\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Layer, Dense, Dropout, Embedding, LSTM, CuDNNLSTM, Bidirectional\n",
        "from keras.layers import Softmax\n",
        "from keras.datasets import imdb\n",
        "\n",
        "def get_lstm(size, return_sequences=True):\n",
        "    return CuDNNLSTM(size, return_sequences=return_sequences)\n",
        "\n",
        "max_features = 20000\n",
        "# cut texts after this number of words\n",
        "# (among top max_features most common words)\n",
        "maxlen = 100\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_val = x_test[0:len(x_test)//2]\n",
        "y_val = x_test[0:len(y_test)//2]\n",
        "x_test = x_test[len(x_test)//2 : ]\n",
        "y_test = x_test[len(y_test)//2 : ]\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "print(len(x_val), 'validation sequences')\n",
        "\n",
        "def compress(x, y):\n",
        "    xout = []\n",
        "    yout = []\n",
        "    for i in range(len(x)):\n",
        "        if x[i][0] != 0:\n",
        "            xout.append(x[i])\n",
        "            yout.append(y[i])\n",
        "    xa = np.array(xout)\n",
        "    print(xa.shape)\n",
        "    return np.array(xout), np.array(yout)\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "x_val = sequence.pad_sequences(x_val, maxlen=maxlen)\n",
        "#y_train = np.array(y_train)\n",
        "#y_test = np.array(y_test)\n",
        "y_train = np.expand_dims(np.array(x_train), -1)\n",
        "y_test = np.expand_dims(np.array(x_test), -1)\n",
        "y_val = np.expand_dims(np.array(x_val), -1)\n",
        "(x_train, y_train) = compress(x_train, y_train)\n",
        "(x_test, y_test) = compress(x_test, y_test)\n",
        "(x_val, y_val) = compress(x_val, y_val)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('x_val shape:', x_val.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)\n",
        "print('y_val shape:', y_val.shape)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.6/dist-packages (1.16.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "12500 test sequences\n",
            "12500 validation sequences\n",
            "Pad sequences (samples x time)\n",
            "(22227, 100)\n",
            "(11012, 100)\n",
            "(11025, 100)\n",
            "x_train shape: (22227, 100)\n",
            "x_test shape: (11012, 100)\n",
            "x_val shape: (11025, 100)\n",
            "y_train shape: (22227, 100, 1)\n",
            "y_test shape: (11012, 100, 1)\n",
            "y_val shape: (11025, 100, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YyrrjKwTDhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/philipperemy/keras-snail-attention/blob/master/attention.py\n",
        "class AttentionBlock(Layer):\n",
        "\n",
        "    def __init__(self, dims, k_size, v_size, seq_len=None, **kwargs):\n",
        "        self.k_size = k_size\n",
        "        self.seq_len = seq_len\n",
        "        self.v_size = v_size\n",
        "        self.dims = dims\n",
        "        self.sqrt_k = math.sqrt(k_size)\n",
        "        self.keys_fc = None\n",
        "        self.queries_fc = None\n",
        "        self.values_fc = None\n",
        "        super(AttentionBlock, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # https://stackoverflow.com/questions/54194724/how-to-use-keras-layers-in-custom-keras-layer\n",
        "        self.keys_fc = Dense(self.k_size)\n",
        "        self.keys_fc.build((None, self.dims))\n",
        "        self._trainable_weights.extend(self.keys_fc.trainable_weights)\n",
        "\n",
        "        self.queries_fc = Dense(self.k_size)\n",
        "        self.queries_fc.build((None, self.dims))\n",
        "        self._trainable_weights.extend(self.queries_fc.trainable_weights)\n",
        "\n",
        "        self.values_fc = Dense(self.v_size)\n",
        "        self.values_fc.build((None, self.dims))\n",
        "        self._trainable_weights.extend(self.values_fc.trainable_weights)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        # check that the implementation matches exactly py torch.\n",
        "        keys = self.keys_fc(inputs)\n",
        "        queries = self.queries_fc(inputs)\n",
        "        values = self.values_fc(inputs)\n",
        "        logits = K.batch_dot(queries, K.permute_dimensions(keys, (0, 2, 1)))\n",
        "        mask = K.ones_like(logits) * np.triu((-np.inf) * np.ones(logits.shape.as_list()[1:]), k=1)\n",
        "        logits = mask + logits\n",
        "        probs = Softmax(axis=-1)(logits / self.sqrt_k)\n",
        "        read = K.batch_dot(probs, values)\n",
        "        output = K.concatenate([inputs, read], axis=-1)\n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_shape = list(input_shape)\n",
        "        output_shape[-1] += self.v_size\n",
        "        return tuple(output_shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWdU04vHTE61",
        "colab_type": "code",
        "outputId": "a1392449-41bf-4052-ef27-eab26abd983f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1743
        }
      },
      "source": [
        "def sparse_categorical_accuracy(y_true, y_pred):\n",
        "    # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n",
        "    if K.ndim(y_true) == K.ndim(y_pred):\n",
        "        y_true = K.squeeze(y_true, -1)\n",
        "    # convert dense predictions to labels\n",
        "    y_pred_labels = K.argmax(y_pred, axis=-1)\n",
        "    y_pred_labels = K.cast(y_pred_labels, K.floatx())\n",
        "    return K.cast(K.equal(y_true, y_pred_labels), K.floatx())\n",
        "\n",
        "def sparse_categorical_accuracy_per_sequence(y_true, y_pred):\n",
        "    # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n",
        "    if K.ndim(y_true) == K.ndim(y_pred):\n",
        "        y_true = K.squeeze(y_true, -1)\n",
        "    # convert dense predictions to labels\n",
        "    y_pred_labels = K.argmax(y_pred, axis=-1)\n",
        "    y_pred_labels = K.cast(y_pred_labels, K.floatx())\n",
        "    return K.min(K.cast(K.equal(y_true, y_pred_labels), K.floatx()), axis=-1)\n",
        "\n",
        "def sparse_categorical_accuracy(y_true, y_pred):\n",
        "    # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n",
        "    if K.ndim(y_true) == K.ndim(y_pred):\n",
        "        y_true = K.squeeze(y_true, -1)\n",
        "    # convert dense predictions to labels\n",
        "    y_pred_labels = K.argmax(y_pred, axis=-1)\n",
        "    y_pred_labels = K.cast(y_pred_labels, K.floatx())\n",
        "    return K.cast(K.equal(y_true, y_pred_labels), K.floatx())\n",
        "\n",
        "def sparse_categorical_accuracy_per_sequence(y_true, y_pred):\n",
        "    # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n",
        "    if K.ndim(y_true) == K.ndim(y_pred):\n",
        "        y_true = K.squeeze(y_true, -1)\n",
        "    # convert dense predictions to labels\n",
        "    y_pred_labels = K.argmax(y_pred, axis=-1)\n",
        "    y_pred_labels = K.cast(y_pred_labels, K.floatx())\n",
        "    return K.min(K.cast(K.equal(y_true, y_pred_labels), K.floatx()), axis=-1)\n",
        "\n",
        "def sparse_top_k_categorical_accuracy(y_true, y_pred, k=5):\n",
        "    # If the shape of y_true is (num_samples, 1), flatten to (num_samples,)\n",
        "    return K.cast(K.in_top_k(y_pred, K.cast(K.flatten(y_true), 'int32'), k),\n",
        "                  K.floatx())\n",
        "\n",
        "def sparse_top_k_categorical_accuracy_per_sequence(y_true, y_pred, k=5):\n",
        "    # If the shape of y_true is (num_samples, 1), flatten to (num_samples,)\n",
        "    return K.cast(K.in_top_k(y_pred, K.cast(K.flatten(y_true), 'int32'), k),\n",
        "                  K.floatx())\n",
        "\n",
        "def sparse(y_true, y_pred):\n",
        "    return sparse_categorical_accuracy(y_true, y_pred)\n",
        "def sequence(y_true, y_pred):\n",
        "    return sparse_categorical_accuracy_per_sequence(y_true, y_pred)\n",
        "def sparse_k(y_true, y_pred):\n",
        "    return sparse_top_k_categorical_accuracy(y_true, y_pred)\n",
        "def sequence_k(y_true, y_pred):\n",
        "    return sparse_categorical_accuracy_top_k_per_sequence(y_true, y_pred)\n",
        "\n",
        "def test_top_k_categorical_accuracy():\n",
        "    y_pred = K.variable(np.array([[0.3, 0.2, 0.1], [0.1, 0.2, 0.7]]))\n",
        "    y_true = K.variable(np.array([[0, 1, 0], [1, 0, 0]]))\n",
        "    success_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n",
        "                                                               k=3))\n",
        "    assert np.mean(success_result) == 1\n",
        "    partial_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n",
        "                                                               k=2))\n",
        "    assert np.mean(partial_result) == 0.5\n",
        "    failure_result = K.eval(metrics.top_k_categorical_accuracy(y_true, y_pred,\n",
        "                                                               k=1))\n",
        "    assert np.mean(failure_result) == 0\n",
        "\n",
        "\n",
        "units=16\n",
        "units_k=units*2\n",
        "units_v=13\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, units*2, input_length=maxlen))\n",
        "model.add(Bidirectional(get_lstm(units, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "if False:\n",
        "    model.add(AttentionBlock(units*2, k_size=units_k, v_size=units_v))  # (80, 37) - looks correct.\n",
        "    #model.add(Dense(units))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(max_features, activation='softmax'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=[sparse, sequence])\n",
        "model.summary()\n",
        "\n",
        "print('Train...')\n",
        "history = None\n",
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=30,\n",
        "          verbose=2,\n",
        "          validation_data=[x_test, y_test])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0620 05:02:57.860814 140073301493632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0620 05:02:57.877881 140073301493632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0620 05:02:57.880655 140073301493632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0620 05:02:58.959769 140073301493632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0620 05:02:58.970731 140073301493632 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0620 05:02:59.014459 140073301493632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0620 05:02:59.035253 140073301493632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0620 05:02:59.135221 140073301493632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 32)           640000    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 100, 32)           6400      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 32)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100, 20000)        660000    \n",
            "=================================================================\n",
            "Total params: 1,306,400\n",
            "Trainable params: 1,306,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train...\n",
            "Train on 22227 samples, validate on 11012 samples\n",
            "Epoch 1/30\n",
            " - 106s - loss: 6.7391 - sparse: 0.0511 - sequence: 0.0000e+00 - val_loss: 6.0531 - val_sparse: 0.0552 - val_sequence: 0.0000e+00\n",
            "Epoch 2/30\n",
            " - 102s - loss: 5.9399 - sparse: 0.0548 - sequence: 0.0000e+00 - val_loss: 5.6475 - val_sparse: 0.0552 - val_sequence: 0.0000e+00\n",
            "Epoch 3/30\n",
            " - 102s - loss: 5.5282 - sparse: 0.0636 - sequence: 0.0000e+00 - val_loss: 5.1243 - val_sparse: 0.1080 - val_sequence: 0.0000e+00\n",
            "Epoch 4/30\n",
            " - 102s - loss: 5.0847 - sparse: 0.0913 - sequence: 0.0000e+00 - val_loss: 4.5454 - val_sparse: 0.2065 - val_sequence: 0.0000e+00\n",
            "Epoch 5/30\n",
            " - 102s - loss: 4.5581 - sparse: 0.1409 - sequence: 0.0000e+00 - val_loss: 3.8015 - val_sparse: 0.3514 - val_sequence: 0.0000e+00\n",
            "Epoch 6/30\n",
            " - 102s - loss: 4.0220 - sparse: 0.2260 - sequence: 0.0000e+00 - val_loss: 3.1745 - val_sparse: 0.5196 - val_sequence: 0.0000e+00\n",
            "Epoch 7/30\n",
            " - 102s - loss: 3.4988 - sparse: 0.3363 - sequence: 0.0000e+00 - val_loss: 2.6274 - val_sparse: 0.6148 - val_sequence: 0.0000e+00\n",
            "Epoch 8/30\n",
            " - 102s - loss: 3.1721 - sparse: 0.3817 - sequence: 0.0000e+00 - val_loss: 2.2821 - val_sparse: 0.6834 - val_sequence: 0.0000e+00\n",
            "Epoch 9/30\n",
            " - 102s - loss: 2.9307 - sparse: 0.4159 - sequence: 0.0000e+00 - val_loss: 1.9925 - val_sparse: 0.7372 - val_sequence: 0.0000e+00\n",
            "Epoch 10/30\n",
            " - 102s - loss: 2.6538 - sparse: 0.4809 - sequence: 0.0000e+00 - val_loss: 1.7179 - val_sparse: 0.7830 - val_sequence: 0.0000e+00\n",
            "Epoch 11/30\n",
            " - 102s - loss: 2.4129 - sparse: 0.5276 - sequence: 0.0000e+00 - val_loss: 1.4983 - val_sparse: 0.8223 - val_sequence: 0.0000e+00\n",
            "Epoch 12/30\n",
            " - 102s - loss: 2.2388 - sparse: 0.5572 - sequence: 0.0000e+00 - val_loss: 1.3206 - val_sparse: 0.8474 - val_sequence: 0.0000e+00\n",
            "Epoch 13/30\n",
            " - 102s - loss: 2.0984 - sparse: 0.5806 - sequence: 0.0000e+00 - val_loss: 1.1802 - val_sparse: 0.8660 - val_sequence: 9.0810e-05\n",
            "Epoch 14/30\n",
            " - 102s - loss: 1.9876 - sparse: 0.5970 - sequence: 0.0000e+00 - val_loss: 1.0677 - val_sparse: 0.8787 - val_sequence: 1.8162e-04\n",
            "Epoch 15/30\n",
            " - 102s - loss: 1.8966 - sparse: 0.6108 - sequence: 0.0000e+00 - val_loss: 0.9751 - val_sparse: 0.8895 - val_sequence: 2.7243e-04\n",
            "Epoch 16/30\n",
            " - 102s - loss: 1.8189 - sparse: 0.6231 - sequence: 0.0000e+00 - val_loss: 0.8984 - val_sparse: 0.8984 - val_sequence: 3.6324e-04\n",
            "Epoch 17/30\n",
            " - 102s - loss: 1.7521 - sparse: 0.6338 - sequence: 0.0000e+00 - val_loss: 0.8336 - val_sparse: 0.9070 - val_sequence: 2.7243e-04\n",
            "Epoch 18/30\n",
            " - 102s - loss: 1.6933 - sparse: 0.6433 - sequence: 0.0000e+00 - val_loss: 0.7784 - val_sparse: 0.9168 - val_sequence: 0.0011\n",
            "Epoch 19/30\n",
            " - 102s - loss: 1.6389 - sparse: 0.6534 - sequence: 0.0000e+00 - val_loss: 0.7299 - val_sparse: 0.9229 - val_sequence: 0.0029\n",
            "Epoch 20/30\n",
            " - 102s - loss: 1.5906 - sparse: 0.6621 - sequence: 0.0000e+00 - val_loss: 0.6868 - val_sparse: 0.9269 - val_sequence: 0.0040\n",
            "Epoch 21/30\n",
            " - 102s - loss: 1.5462 - sparse: 0.6700 - sequence: 0.0000e+00 - val_loss: 0.6494 - val_sparse: 0.9317 - val_sequence: 0.0058\n",
            "Epoch 22/30\n",
            " - 103s - loss: 1.5080 - sparse: 0.6766 - sequence: 0.0000e+00 - val_loss: 0.6175 - val_sparse: 0.9358 - val_sequence: 0.0078\n",
            "Epoch 23/30\n",
            " - 103s - loss: 1.4732 - sparse: 0.6826 - sequence: 0.0000e+00 - val_loss: 0.5888 - val_sparse: 0.9392 - val_sequence: 0.0105\n",
            "Epoch 24/30\n",
            " - 103s - loss: 1.4402 - sparse: 0.6882 - sequence: 0.0000e+00 - val_loss: 0.5624 - val_sparse: 0.9418 - val_sequence: 0.0127\n",
            "Epoch 25/30\n",
            " - 102s - loss: 1.4101 - sparse: 0.6932 - sequence: 0.0000e+00 - val_loss: 0.5390 - val_sparse: 0.9442 - val_sequence: 0.0153\n",
            "Epoch 26/30\n",
            " - 103s - loss: 1.3834 - sparse: 0.6979 - sequence: 0.0000e+00 - val_loss: 0.5179 - val_sparse: 0.9476 - val_sequence: 0.0190\n",
            "Epoch 27/30\n",
            " - 103s - loss: 1.3589 - sparse: 0.7027 - sequence: 0.0000e+00 - val_loss: 0.4983 - val_sparse: 0.9502 - val_sequence: 0.0244\n",
            "Epoch 28/30\n",
            " - 103s - loss: 1.3334 - sparse: 0.7077 - sequence: 0.0000e+00 - val_loss: 0.4801 - val_sparse: 0.9526 - val_sequence: 0.0289\n",
            "Epoch 29/30\n",
            " - 102s - loss: 1.3120 - sparse: 0.7117 - sequence: 0.0000e+00 - val_loss: 0.4624 - val_sparse: 0.9553 - val_sequence: 0.0341\n",
            "Epoch 30/30\n",
            " - 102s - loss: 1.2905 - sparse: 0.7156 - sequence: 0.0000e+00 - val_loss: 0.4471 - val_sparse: 0.9573 - val_sequence: 0.0400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHy1cTDVP_XZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "079c2330-38e9-41a9-a791-e3c33f71e472"
      },
      "source": [
        "\n",
        "if history != None:\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['sparse'])\n",
        "  plt.plot(history.history['val_sparse'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('sparse_categorical_accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XeYVOX1wPHvYXfZXln60nuvYkXB\nEhF7Q0HsEX/RJJqoiYklapqJxmjsJRobGjv2DhgVkCa994WFXRbY3vf8/rh3YRZ2YWd3Zmdn5nye\nZ565Ze6dcxn2nnvf973vK6qKMcYYU6NVoAMwxhjTslhiMMYYU4slBmOMMbVYYjDGGFOLJQZjjDG1\nWGIwxhhTiyUGE3ZE5D8i8qcGfnaziJzq75iMaUksMRhjjKnFEoMxQUpEIgMdgwlNlhhMi+QW4dwm\nIktFpEhE/i0i7UXkExEpEJEvRSTV4/PniMgKEdknIrNEZIDHuhEissjd7r9AzEHfdZaI/Ohu+72I\nDG1gjGeKyGIRyReRbSJyz0HrT3D3t89df5W7PFZE/iEiW0QkT0S+dZeNE5HMOv4dTnWn7xGRt0Tk\nFRHJB64SkTEiMsf9jiwReUxEWntsP0hEvhCRPSKyS0R+LyIdRKRYRNp4fG6kiOSISFRDjt2ENksM\npiW7EDgN6AucDXwC/B5oi/N/95cAItIXeA242V33MfCBiLR2T5LvAS8DacCb7n5xtx0BPA9cD7QB\nngbeF5HoBsRXBFwBpABnAj8TkfPc/XZz433UjWk48KO73YPAKOA4N6bfANUN/Dc5F3jL/c5XgSrg\nV0A6cCxwCnCDG0Mi8CXwKdAJ6A18pao7gVnAJI/9Xg68rqoVDYzDhDBLDKYle1RVd6nqduB/wDxV\nXayqpcC7wAj3c5cAH6nqF+6J7UEgFufEewwQBTysqhWq+hYw3+M7pgFPq+o8Va1S1ReBMne7w1LV\nWaq6TFWrVXUpTnI6yV09BfhSVV9zvzdXVX8UkVbANcBNqrrd/c7vVbWsgf8mc1T1Pfc7S1R1oarO\nVdVKVd2Mk9hqYjgL2Kmq/1DVUlUtUNV57roXgakAIhIBTMZJnsZYYjAt2i6P6ZI65hPc6U7AlpoV\nqloNbAM6u+u2a+3eIrd4THcDbnGLYvaJyD6gi7vdYYnI0SIy0y2CyQP+D+fKHXcfG+rYLB2nKKuu\ndQ2x7aAY+orIhyKy0y1e+ksDYgCYAQwUkR44d2V5qvpDI2MyIcYSgwkFO3BO8ACIiOCcFLcDWUBn\nd1mNrh7T24A/q2qKxytOVV9rwPdOB94HuqhqMvAUUPM924BedWyzGyitZ10REOdxHBE4xVCeDu4O\n+UlgNdBHVZNwito8Y+hZV+DuXdcbOHcNl2N3C8aDJQYTCt4AzhSRU9zK01twioO+B+YAlcAvRSRK\nRC4Axnhs+yzwf+7Vv4hIvFupnNiA700E9qhqqYiMwSk+qvEqcKqITBKRSBFpIyLD3buZ54GHRKST\niESIyLFuncZaIMb9/ijgTuBIdR2JQD5QKCL9gZ95rPsQ6CgiN4tItIgkisjRHutfAq4CzsESg/Fg\nicEEPVVdg3Pl+yjOFfnZwNmqWq6q5cAFOCfAPTj1Ee94bLsAuA54DNgLrHc/2xA3APeJSAFwN06C\nqtnvVmAiTpLag1PxPMxdfSuwDKeuYw/wN6CVqua5+3wO526nCKjVSqkOt+IkpAKcJPdfjxgKcIqJ\nzgZ2AuuA8R7rv8Op9F6kqp7FaybMiQ3UY0z4EpGvgemq+lygYzEthyUGY8KUiBwFfIFTR1IQ6HhM\ny2FFScaEIRF5EecZh5stKZiD+fWOQUSex2lLna2qg+tYL8AjOGWxxcBVqrrIbwEZY4w5In/fMfwH\nmHCY9WcAfdzXNJymd8YYYwLIr51wqeo3ItL9MB85F3jJffhoroikiEhHVc063H7T09O1e/fD7dYY\nY8zBFi5cuFtVD3425hCB7p2xM7Wf5Mx0lx2SGERkGs5dBV27dmXBggXNEqAxxoQKEWlQs+SgqXxW\n1WdUdbSqjm7b9ogJzxhjTCMFOjFsx+m6oEaGu8wYY0yABDoxvA9c4XZFcAxOR16HrV8wxhjjX36t\nYxCR14BxQLo7AMkfcLpARlWfwuk3fyJONwTFwNWN/a6KigoyMzMpLS1tatgtWkxMDBkZGURF2Xgq\nxhj/8HerpMlHWK/Ajb74rszMTBITE+nevTu1O9IMHapKbm4umZmZ9OjRI9DhGGNCVKCLknymtLSU\nNm3ahGxSABAR2rRpE/J3RcaYwAqZxACEdFKoEQ7HaIwJrEA/x2CMMeFLFSpKoLwQyouc6Ypid7rY\nnS72WFYCQy6Gtn39GpYlBh/Zt28f06dP54YbbvBqu4kTJzJ9+nRSUlL8FJkxxqdUoaocygqhvMA5\nYR8yXQhlBR6vfOe91H0vyzuwrrrSiy8X6DjMEkOw2LdvH0888cQhiaGyspLIyPr/mT/++GN/h2aM\n8VRRAiV7D33VOpHX8SqvmS6E6oqGfVerKIhJguhEiE5yXildIHqgO5944BUVB63jICoeomIPTHsu\ni4qFZihOtsTgI7fffjsbNmxg+PDhREVFERMTQ2pqKqtXr2bt2rWcd955bNu2jdLSUm666SamTZsG\nQPfu3VmwYAGFhYWcccYZnHDCCXz//fd07tyZGTNmEBsbG+AjM6aFqKo8cOVdXlj/VXp50YH1ZfmH\nJoDKIzTeiIqvfcKOToD4HgfmWyc4y1rXvOJrz3tOR0Y3y4nc10IyMdz7wQpW7sj36T4HdkriD2cP\nqnf9/fffz/Lly/nxxx+ZNWsWZ555JsuXL9/frPT5558nLS2NkpISjjrqKC688ELatGlTax/r1q3j\ntdde49lnn2XSpEm8/fbbTJ061afHYUzAVJZD6b66r9ZL9kJp3qFFLzWv0nyoLGnY97SK9DhJJ0Jc\nGqT1hNgUiE2D2NQ6XikHruBbRfj33yEIhGRiaAnGjBlT61mDf/3rX7z77rsAbNu2jXXr1h2SGHr0\n6MHw4cMBGDVqFJs3b262eI3xiqpzVV6UA0W73VcOFHtM1yyvOfFXFNW/P2nlnJhjkg6coOPbOif0\n/VfuNes8r8wTPa7Y3ekgvUpvSUIyMRzuyr65xMfH75+eNWsWX375JXPmzCEuLo5x48bV+SxCdHT0\n/umIiAhKShp4hWSMr6g6J/GCLCjY6bwK3feCLCjY5UwXZddfJNM6AeLTIS4dkjtDx6EQk3Lgyryu\nK/boJGgVUq3ng1pIJoZASExMpKCg7hES8/LySE1NJS4ujtWrVzN37txmjs6EtYoSjyv6XI+r+YPn\ndztJoKr80H3EJENiR0hoD92Og4R2zhV9fLrzHtfmwHyU1YsFO0sMPtKmTRuOP/54Bg8eTGxsLO3b\nt9+/bsKECTz11FMMGDCAfv36ccwxxwQwUhNyygohbxvs3QL7tsK+Le5rq/Mq2Vv3dhHR7pW9e1JP\n7+Oc+BM7QmIH9709JHRwWsaYsOHXMZ/9ZfTo0XrwQD2rVq1iwIABAYqoeYXTsRoPJfsgawnsWOy8\n793sJIDi3Nqfi4yBlK6Q0s15T+rkXs3XXOG7xTzRiVYWH2ZEZKGqjj7S5+yOwZiWqKwAspY6SaDm\ntWfDgfUpXaFNb6f8viYBpHSD1G5OArATvmkCSwzGBFrRbti1HHatOJAMdq8F3Lv5pAzoNByGT4FO\nI5xXXFpAQzahzRKDMc2lstw54e9aAbuWue8roHDXgc8kdIDOI2HwhW4SGO5U9BrTjCwxGOMPhdmw\nc5lzJ7DTvRvYveZAvzgR0dCuP/Q+FdoPcl7tBkGCjWduAs8SgzFNUVUBu9e5CcAjERRlH/hMUmdo\nPxj6TXCTwGBI6wUR9udnWib7n2lMQ6lC7nrYNg+2/eDUBeSsPtDuP6I1tO0PfU5zTv4dhjiJwOoD\nTJCxxOAjje12G+Dhhx9m2rRpxMVZW/EWpawQti+EzB+cRJA5/8AzAdHJ0HkEHH09dBjqJIL0PhBh\nY3Gb4GeJwUfq63a7IR5++GGmTp1qiSHQCnbCpm/cO4J5Tr2AVjvr0vtB/zOhy9GQMQbS+1oXDiZk\nWWLwEc9ut0877TTatWvHG2+8QVlZGeeffz733nsvRUVFTJo0iczMTKqqqrjrrrvYtWsXO3bsYPz4\n8aSnpzNz5sxAH0r4KM2HLd/BxlnOK2e1s7x1AmSMhrG3QpcxznRsaiAjNaZZhWZi+OR2pyLQlzoM\ngTPur3e1Z7fbn3/+OW+99RY//PADqso555zDN998Q05ODp06deKjjz4CnD6UkpOTeeihh5g5cybp\n6em+jdnUVlnuFAdtnAWbZkPmAtAqiIyFbsc6zwn0OMn5ra3rZRPGQjMxBNjnn3/O559/zogRIwAo\nLCxk3bp1jB07lltuuYXf/va3nHXWWYwdOzbAkYaB0nxY/jas/si5O6godrp47jQSTvgV9Bzn3BVE\nRh9pT8aEjdBMDIe5sm8Oqsrvfvc7rr/++kPWLVq0iI8//pg777yTU045hbvvvjsAEYY4VdjyPSx+\nBVa+5ySDtF4wYqqTCLod73T/bIypU2gmhgDw7Hb79NNP56677uKyyy4jISGB7du3ExUVRWVlJWlp\naUydOpWUlBSee+65WttaUVITFeyEH6c7CWHPBmfglqGTYMQVztPE1n+QMQ1iicFHPLvdPuOMM5gy\nZQrHHnssAAkJCbzyyiusX7+e2267jVatWhEVFcWTTz4JwLRp05gwYQKdOnWyymdvVVXA2s9g8cuw\n7gunzqDb8XDirTDwXGdEL2OMV6zb7SAUTsdar8IcmPOYc4dQlO30MTR8Moy4HNr0CnR0xrRI1u22\nCU0l++D7R2Huk87Qkv3OcJJB71OtiwljfMT+kkxwKC+CeU/Bd49AaZ7T++i430N670BHZkzICanE\noKpIiFcwBmPRX5NUlsGCF+B/DzpjE/edAOPvcAaoMcb4RcgkhpiYGHJzc2nTpk3IJgdVJTc3l5iY\nmECH4n9VlbBkOsz6G+RnQvexcOl055kDY4xfhUxiyMjIIDMzk5ycnECH4lcxMTFkZGQEOgz/qa6G\nFe/ArL86PZl2HgXnPuY8fxCiCd+YliZkEkNUVBQ9evQIdBimKYr3wFtXO11WtBvo3CH0m2gJwZhm\n1uDEICJnAx+p1nQ3aYwPZa+C1y6F/B1w1j9h5JXWX5ExAeJNv8GXAOtE5O8i0r+hG4nIBBFZIyLr\nReT2OtZ3FZGZIrJYRJaKyEQvYjKhYPVH8NypUFECV30Mo6+xpGBMADU4MajqVGAEsAH4j4jMEZFp\nIpJY3zYiEgE8DpwBDAQmi8jAgz52J/CGqo4ALgWe8PIYTLBShdkPwOtTnPENps2CLkcFOipjwp5X\nI42oaj7wFvA60BE4H1gkIr+oZ5MxwHpV3aiq5e525x68WyDJnU4GdngTkwlS5UXw5lUw808w9BK4\n+mNI6hToqIwxeFfHcA5wNdAbeAkYo6rZIhIHrAQerWOzzsA2j/lM4OiDPnMP8LmbXOKBUxscvQlO\n+7bCa1MgewWc9kc47hdWwWxMC+JNq6QLgX+q6jeeC1W1WESubUIMk4H/qOo/RORY4GURGXxwJbeI\nTAOmAXTt2rUJX2cCavN38MblznMKU96EPnYdYExL401R0j3ADzUzIhIrIt0BVPWrerbZDnTxmM9w\nl3m6FnjD3c8cIAY4pP9pVX1GVUer6ui2bdt6EbZpMeb/G146B2LT4LqvLCkY00J5kxjeBDyv4qvc\nZYczH+gjIj1EpDVO5fL7B31mK3AKgIgMwEkMof2UWripqoQPfwUf/Rp6jneSQnqfQEdljKmHN0VJ\nkW4FMgCqWu6e7OulqpUi8nPgMyACeF5VV4jIfcACVX0fuAV4VkR+hVMRfZWGXYdAIayyHN6+Fla9\nD8f9Ek69x5qiGtPCeZMYckTkHPdkjoicC+w+0kaq+jHw8UHL7vaYXgkc70UcJlhUlMB/L4f1X8Dp\nf4Fjbwx0RMaYBvAmMfwf8KqIPAYITmujK/wSlQl+ZQXw2mTY/C2c/QiMuirQERljGqjBiUFVNwDH\niEiCO1/ot6hMcCvZC69cBDsWwwXPwtCLAx2RMcYLXnWiJyJnAoOAmJqurVX1Pj/EZYJVYQ68fD7s\nXgOTXoIBZwU6ImOMl7x5wO0pIA4YDzwHXIRH81VjyN8BL50L+7bB5Neh9ymBjsgY0wjeNFc9TlWv\nAPaq6r3AsUBf/4Rlgs7ezfD8BMjPgsvfsaRgTBDzpiip1H0vFpFOQC5Of0km3OWsde4UKkvgyhnO\n4DrGmKDlTWL4QERSgAeARTjPHDzrl6hM8Mha6tQpSCu46iNoPyjQERljmqhBiUFEWgFfqeo+4G0R\n+RCIUdU8v0ZnWrbMhfDK+dA6Ea6YAem9Ax2RMcYHGlTH4HZo97jHfJklhTCXsxZevRBiU+GaTywp\nGBNCvKl8/kpELhSx/pHDXn4WvHIhtIqEy9+DFOvt1phQ4k1iuB6n07wyEckXkQIRyfdTXKalKs2D\nVy+Gkj1w2ZuQ1iPQERljfMybJ5/rHcLThInKcvjvVMhZBVPegE4jAh2RMcYPvHnA7cS6lh88cI8J\nUdXV8N7PYNM3cP7T9pyCMT6kqhSUVbKnsJzconL2FpWzp6icPcXuu8fr9xMHMKZHml/j8aa56m0e\n0zE44zkvBE72aUSmZfriLlj+ltNt9rBLAx2NMS2aqpJfUsnuojL2FJWTW1hOblHZ/hP/niJnPrfQ\nmd5bXE5FVd2jDbSObEWb+Nakua/mqOX1pijpbM95EekCPOzziEzLM+dxmPMYjJkGx98c6GiMCaiy\nyiqy88vYlV/KzvxSduaVutPOsl3usrLK6jq3T4yOJC3BOclnpMYxLCOF1PjWB07+Ca1JizuQCOJa\nR9DcbX686kTvIJnAAF8FYlqoZW/BZ7+HgefChPtplssVYwKgtKKKnIIysgtKyc4vI7vAOdFnFzjT\n2e70nqLyQ7ZtHdmKDkkxdEiKYWhGCqcNiKZ9Ugzpia1pEx9NWnxr2rjJIDqy5Q9U5U0dw6M4TzuD\n05ppOM4T0CZUbZwN7/4fdDsezn/GRl4zQamwrHL/Sb3mBJ9TM+2RBPJKKg7ZNrKV0DYxmnaJ0WSk\nxjGqWyrtEmPokOyc+DskO8kgOTaq2a/q/cmbO4YFHtOVwGuq+p2P4zEtxc5l8Ppl0KY3XPoqRMUE\nOiJjaimvrHav6EvZmVfGzvxSsj2Kd2qu+IvLqw7ZtnVEK+eEnxRNz7bxHNOzDe2TommXGEPbpGja\nJ8bQLimatLjWtGoVOif8hvImMbwFlKpqFYCIRIhInKoW+yc0EzB7tzgD7cQkwdS3naebjWlGVdVK\ndkEpO/aVsH2f8+68nOld+aXk1lOk0z4pmg5JMQzqlMT4fu1ol+Rc8bdzT/btEqND7grf17xJDF8B\npwI1I7fFAp8Dx/k6KBNAZQXw6kVOT6nXfAbJnQMdkQlBZZVV7NhXSubeYjL3lpC5t5jte50T//Z9\nJezML6WqunYrnaSYSDqlxNIxOYZhXVKcMv3kaNq5ZfsdkmJIibMTvi94kxhiPIfzVNVCEYnzQ0wm\nkD69HXLXwxXvQztrW2Aap7Kqmqy8UrbuKWbbngMnf+e9hF0FpajHeT+yldAhOYbOKbGM6ZFGp5QY\nOqXE0iklls5uMkiMiQrcAYUZbxJDkYiMVNVFACIyCijxT1gmIFa+D4tfgbG3Qo+xgY7GtHBFZZVs\n3VPMllzn5L9lTxFbcovZuse5+q/0uOKPaCV0TI6hS2ocY/ukk5EaR0ZqrPNKi6N9YjSREd700GP8\nyZvEcDPwpojsAAToAFzil6hM8yvYCR/cBB2Hw7jbAx2NaSFUlZyCMtZlF7J2VwHrsgtZv6uQjbsL\n2V1Yu4w/OTaKbm3iGNI5mbOGdqRrWhxd0+LpkhZLh6QYO/EHEW8ecJsvIv2Bfu6iNap6aPsuE3xU\nYcaNUFECFzwLEXbLHm5UlZ35pazdVci6XQWszy5kXbYznV9auf9zSTGR9G2fyMn929GtTTzd2sTR\nNS2ObmnxJMfZ/5tQ4c1zDDcCr6rqcnc+VUQmq+oTfovONI/5z8H6L2Hig9DWhvEOdaUVVazdVcCq\nrHxWZTnvq3cW1GrHnxoXRZ/2iZw9rBN92yfSp10Cvdsn0DYh2ip3w4A3RUnXqarnYD17ReQ6wBJD\nMMtZA5/fCb1Pg6N+GuhojI9l55eyfEfe/gSwKiufTbuLqCn+j42KoF+HRCYO6ciAjon7k0CbhOjA\nBm4CypvEECEiouq0JRCRCKC1f8IyzaKyHN65DlrHw7mPW3cXQS6vpIJlmXksydzHkm37WJqZx878\n0v3rM1JjGdAxiTOHdGRAxyT6d0yiW1pcWD7AZQ7Pm8TwKfBfEXnanb/eXWaC1ez7IWsJXPIqJLYP\ndDTGC6UVVazYkc9SjySwcXfR/vU90uM5umcawzJSGJKRTL8OiSRZc0/TQN4kht/iJIOfufNfAM/5\nPCLTPLbMgW//CSOmwoCzAh2NOYyS8ipWZuWzYkceyzLzWLY9j3XZhfsfAGufFM2wjBQuHJXB0Ixk\nhnZOsYpg0yTetEqqBp50XyaYlebDu9OcsZon3B/oaIyH4vJKVu7IZ9n2PJZvz2f59jzW5xxIAm3i\nWzO4czKnDGjH0IwUhmWk0CHZ+rEyvuVNq6Q+wF+BgTgD9QCgqj39EJfxp09vh7xMp8uLaBuxNVCq\nq5WNu4tYtHUvi7fuY/HWvazdVbC/Yjg9IZohnZM4fVB7BnVOZkjnZDomx1irION33hQlvQD8Afgn\nMB64Gqf7bRNMVs6AH1+FE38DXcYEOpqwUlBawZJteSzaund/MqhpIpoYE8mIrqn8ZFAHhrhJoH2S\nNQ01geFNYohV1a/clklbgHtEZCFwt59iM76Wn+U83dxpJJz0m0BHE/KyC0qZsyGXuRv3sHjrXtbs\nKkDVafzVp10CZwzuwMiuqYzomkKvtgnWOsi0GN4khjIRaQWsE5GfA9uBBP+EZXyuuhpm3AAVpXDB\nM/Z0sx/sKSpn3sZcvt+Qy5yNuazPdvqcTIyOZGS3VCa4iWB41xRrIWRaNG8Sw01AHPBL4I84xUlX\n+iMo4wcLn4cNX8OZD0F6n0BHExLySir4YdMe5mzI5fsNu1m9swCAuNYRHNU9jYtHZXBsrzYM6pRM\nhN0NmCDiVV9J7mQhTv1CLSLyqKr+oo7lE4BHgAjgOVU9pBmMiEwC7sEZOnSJqk5paFymAcqLYNb9\n0O0EGH1NoKMJWtXVyvIdecxcncOstdks2baPaoXoyFaM7p7KrT/py7G92jA0I4Uo6zDOBDFv7hiO\n5PiDF7hPRz8OnAZkAvNF5H1VXenxmT7A74Dj3W422vkwJgMw/99QlAOTXranm72UV1zBN+tymLkm\nm2/W5rC7sBwRGJqRws/H9+a43ukM75JCTJSNh21Chy8TQ13GAOtVdSOAiLwOnAus9PjMdcDjqroX\nQFWz/RxTeCkrhO8ehp7joduxgY6mxVNVVuzIZ/baHGauzmbR1r1UK6TERXFS37aM69eWE/u0tb6E\nTEjzd2LoDGzzmM8Ejj7oM30BROQ7nOKme1T1kK42RGQaMA2ga9eufgk2JM1/FopzYfzvAx1Ji1Vd\nrSzetpcPlmTxyfIsduWXATCkczI/H9+bcf3bMSwjxeoJTNjwZWJo7F9NJNAHGAdkAN+IyBBV3ef5\nIVV9BngGYPTo0XrwTkwdygrgu0eg96n2zMJBVJWlmXl8uHQHHy3NYkdeKa0jWzG+X1tOG9iBk/q2\npW2i3RWY8OTLxPBIHcu2A1085jPcZZ4ygXnuoD+bRGQtTqKYj2maeU9DyV4YZ3cL4CSDlVn5fLg0\ni4+WZrF1TzFREcKJfdpy24R+nDqgvY0rbAwNSAwi8gFOa6E6qeo57vt/6lg9H+gjIj1wEsKlwMEt\njt4DJgMviEg6TtHSxoYEbw6jNB++fxT6nA4ZowIdTUBtzS3mrYXb+HBpFht3FxHRSji+dzo/P7k3\npw/sYB3OGXOQhtwxPNjYnatqpfsw3Gc49QfPq+oKEbkPWKCq77vrfiIiK4Eq4DZVzW3sdxrXvKeg\ndF9Yj9+8IaeQx2euZ8aPO1BVju7Rhp+O7cmEwR1Ii7ehRIypj7jj7gSV0aNH64IFCwIdRstVsg8e\nGQrdjofJrwU6mma3ZmcBj369jo+WZREd2YopY7px3Yk96JgcG+jQjAkoEVmoqqOP9DnrXTUUzXsK\nSvPC7m5h+fY8Hv16HZ+t2EV86wiuP7EXPx3bg3RrWmqMV6x31VBTshfmPA79z4KOwwIdTbNYtHUv\nj329nq9XZ5MYE8kvT+7N1cf3INWKi4xpFOtdNdTMeQLK8sPibmH+5j088uU6vl2/m9S4KG79SV+u\nOK67dVBnTBNZ76qhpHgPzH0SBpwDHYYEOhq/2ZVfyh8/XMmHS7NIT4jm9xP7c9nR3YiP9vfzmsaE\nB+tdNZTMeQzKC2Hc7wIdiV9UVSsvzdnMPz5fS3lVNTef2ofrT+xFbGvrp8gYX/JZ76omwIpynQfa\nBp0H7QcGOhqfW7JtH3e8t4zl2/MZ2yedP547mO7p8YEOy5iQ5E2rpC+Ai2u6qhCRVOB1VT3dX8EZ\nL3z/L6d77ZNCq24hr6SCBz5bzavzttI2IZrHpozgzCEdbchLY/zIm6KkdM/+i6yL7BakaDf88CwM\nvhDa9Q90ND6hqrz343b+/NEq9hSVc9Vx3fn1aX2tywpjmoE3iaFaRLqq6lYAEenGYbrKMM3ou0eg\nsgRO+m2gI/GJ9dmF3PXecuZszGVYlxT+c/UYBndODnRYxoQNbxLDHcC3IjIbpyfVsbjdYJsAKsx2\n7haGXAxt+wY6miZ74btN/OXjVcRGRfCn8wYzeUxX6+7amGbmTeXzpyIyEjjGXXSzqu72T1imwb57\nBKrK4MTfBDqSJnvs63U8+PlaTh3Qnr9eMMS6vTYmQBrSu2p/VV3tJgWAHe57V7doaZH/wjOHVbLP\nGbZz6CWQ3jvQ0TSaqvLPL9byr6/Xc/6Izjxw0VAibcxkYwKmIXcMv8YpMvpHHesUONmnEZmG2zjT\nqVsYGbyPk6gq93+6mqdnb+Skrmy7AAAaC0lEQVSS0V34ywVDrOjImAA7YmJQ1WnuE893qup3zRCT\naah1X0JMMmQcFehIGkVVufeDlfzn+81cfkw37j1nEK0sKRgTcA26X1fVauAxP8divFFdDeu/gF4n\nQ0TwdQVRXa3c8d5y/vP9Zq49oQf3nWtJwZiWwpuC3K9E5EKxJ4tahl3LoHAX9D4t0JF4rapa+c3b\nS5k+bys3jOvFnWcOsAfWjGlBvLnUvB6nvqFKREpwmqyqqib5JTJzeOu+cN57nxrYOLxUWVXNLW8u\nYcaPO/jVqX355Sm9LSkY08J401w10Z+BGC+t/xI6DIXE9oGOpMHKK6u56fXFfLJ8J7+d0J+fjesV\n6JCMMXXwqnBaRM4BTnRnZ6nqh74PyRxRyV7Y9gOc8KtAR9JgZZVV3PjqIr5clc1dZw3k2hN6BDok\nY0w9vOlE737gKOBVd9FNInK8qoZmH88t2YaZoFXQJzjqFyqqqpn20kJmr83hj+cN5vJjugU6JGPM\nYXhzxzARGO62UEJEXgQWA5YYmtt6t5lq5yOO6d0iPPjZGmavzeH+C4Zw6ZiugQ7HGHME3j5emuIx\nbb2aBUJ1tZMYgqSZ6sw12Tz9zUYuO7qrJQVjgoQ3Z5a/AotFZCZOi6QTgdDq/D8YBFEz1V35pdzy\nxhL6d0jkrrNCb/AgY0KVN62SXhORWTj1DAC/VdWdfonK1C9ImqlWVSs3vb6YkvIqHpsykpgoG37T\nmGDhTeVzTSd6me57JxGJB7aoaqXPIzN1W/cFdBzW4pupPvr1OuZu3MODFw+jd7uEQIdjjPGCN0VJ\nTwAjgaU4RUmDgRVAsoj8TFU/90N8xlPJXsj8AU74daAjOay5G3P511fruGBEZy4alRHocIwxXvKm\n8nkHMEJVR6vqKGAEsBE4Dfi7P4IzB9kwE7S6RTdTzS0s46bXF9O9TTx/PG9woMMxxjSCN4mhr6qu\nqJlR1ZVAf1Xd6PuwTJ3WfwkxKS22mWp1tXLLm0vYW1zBo1NGEB/d8ltNGWMO5c1f7goReRJ43Z2/\nBFgpItFAhc8jM7UFQTPV577dyKw1Odx37iAGdbLWzMYEK2/uGK4C1gM3u6+N7rIKYLyvAzMH2bnU\naabaQouRFm/dy98/XcOEQR3syWZjgpw3zVVLROQJ4ENVXXPQ6kLfhmUOsb7lNlPNK6ngF68tpn1S\nDH+7aKj1lmpMkGvwHYPbgd6PwKfu/HARed9fgZmDrPvSaaaa0C7QkdSiqtz+9lJ25pXy6JQRJMdG\nBTokY0wTeVOU9AdgDLAPQFV/BKyLzOZQ00y1z08CHckhXpm3lU+W7+TW0/sxsmtqoMMxxviAN4mh\nQlXzDlqmvgzG1KOmmWoL6wZj+fY8/vjhSk7s25ZpY3sGOhxjjI942yppChAhIn2AXwLf+ycsU0tN\nM9WMltFMVVV5ff427vtgJalxUTw0aZiN12xMCPHmjuEXwCCgDJgO5AE3HWkjEZkgImtEZL2I1Nvp\nnjuetIpIyzj7tRTV1U43GL1OhlaB729oT1E5015eyO/eWcbIbinMuPEE0hOiAx2WMcaHvLljOFNV\n7wDuqFkgIhcDb9a3gYhEAI/jPB2dCcwXkffdh+M8P5eIk2TmeRFPeNi5FIqyW0Qz1W/W5nDLm0vI\nK67gjokDuPaEHnanYEwI8uaOoa4BeY40SM8YYL2qblTVcpyH486t43N/BP4GlHoRT3hoAc1USyuq\nuO+DlVzx/A8kx0bx7o3Hcd2JPS0pGBOijnjHICJn4Ize1llE/uWxKgk4Uq+qnYFtHvOZwNEH7X8k\n0EVVPxKR2w4TxzRgGkDXrmE04Mu6L6Hj8IA1U12zs4CbXl/M6p0FXHlsN343cYB1oW1MiGtIUdIO\nYAFwDrDQY3kB0KTR6EWkFfAQzhPUh6WqzwDPAIwePTo8WkPVNFMde0uzf7Wq8uL3m/nLJ6tJionk\nhauOYnz/lvUMhTHGP46YGFR1CbBERKarqrd9Im0HunjMZ7jLaiTidN89y31atgPwvoico6oLvPyu\n0LPh64A0U80uKOW2N5cye20O4/u15e8XDaNtolUwGxMuvKl87i4ifwUGAjE1C1X1cA3Y5wN9RKQH\nTkK4FJjisW0ekF4z744Qd6slBde6LyE2tVmbqS7fnsdVL/xAQWklfzx3EFOP6WZdXBgTZrxJDC/g\nPP38T5xO867mCJXXqlopIj8HPgMigOdVdYWI3AcsUFXrUqM+nr2pNlMz1fmb93DNC/NJio1i+i+O\noW/7xGb5XmNMy+JNYohV1a9ERFR1C3CPiCwE7j7cRqr6MfDxQcvq3EZVx3kRT2iraabaTMVIs9fm\ncP3LC+iUHMsrPz2aTimxzfK9xpiWx5vEUOZWFq9z7wK2AzaYr7/sb6Z6it+/6tPlWfzitcX0bpfI\ny9eOsQfWjAlz3jzHcBMQh9MVxihgKnClP4IyOE87N0Mz1bcXZnLDq4sY0jmZ1687xpKCMcar8Rjm\nu5OFOPULxl+K90DmfBh7q1+/5qU5m7l7xgqO792GZy4fbUNxGmMA78Zj+EJEUjzmU0XkM/+EFeY2\nur2p+rEbjMdnrufuGSs4bWB7/n3lUZYUjDH7eXM2SFfVfTUzqrpXROyJJ39Y86nTTLXzKJ/vWlX5\n26dreGr2Bs4b3okHLh5GVIQ3JYrGmFDnzRmhWkT290UhIt2w8Rh8r6IU1nwC/c/0eTPV6mrlrhnL\neWr2Bi47uisPTRpuScEYcwhv7hjuAL4VkdmAAGNx+y4yPrThaygvgIHn+3S3lVXV3PbWUt5dvJ3r\nT+rJ7RP624Nrxpg6eVP5/Knb4d0x7qKbVXV3zXoRGaSqK3wdYNhZ+Z4zKE/Pk3y62wc+X8O7i7dz\n2+n9uGFcL0sKxph6eVXj6CaCD+tZ/TIwsskRhbPKMqcYacA5EBHls90WlFbw6tytnDOsEzeO7+2z\n/RpjQpMvC5jtErSpNnwNZfkwyLfFSG8uyKSwrJKfju3h0/0aY0KTLxODVUQ31QrfFyNVVSv/+X4z\no7ulMjQj5cgbGGPCnjVJaSkqy2DNx9D/LJ8WI329Opute4q5+ni7WzDGNIwvE0O5D/cVfjbMdIuR\nzvPpbp//dhOdkmM4fVB7n+7XGBO6vHnyWURkqojc7c53FZExNetV9Zj6tzZHtPI9iEmGHr4rRlq5\nI585G3O58rjuRNrzCsaYBvLmbPEEcCww2Z0vAB73eUThqLIMVrvFSJGtfbbbF77bRGxUBJceFUZj\nZBtjmsyb5qpHq+pIEVkM+7vE8N1ZLJxtmAlleTDQd8VIuwvLmLFkB5NGZ5Ac57s6C2NM6PPmjqFC\nRCJwWx+JSFug2i9RhZuaYqSe43y2y+nztlJeWc1Vx1mlszHGO94khn8B7wLtROTPwLfAX/wSVTip\nKUbqd6bPipHKK6t5ee4WxvVrS+92NpaSMcY73nSJ8ao7lOcpOA+znaeqq/wWWbjYOMspRvJha6SP\nlu0gp6DMmqgaYxrFm1ZJvYBNqvo4sBw4zXN8BtNIK96D6GToOd4nu1NV/v3tJnq3S+DEPuk+2acx\nJrx4U5T0NlAlIr2Bp4EuwHS/RBUuKsthzUfQf6LPipEWbNnL8u35XH18d+sozxjTKF6Nx6CqlcAF\nwGOqehvQ0T9hhYmNs6DUt62Rnv92E8mxUVwwIsNn+zTGhBdvWyVNBq7gQA+r1g6yKVa+B9FJ0Ms3\nxUiZe4v5bMVOJo/pSmxr3w7yY4wJH94khqtxHnD7s6puEpEeOF1tm8aoLIfVH0K/iRAZ7ZNdvjRn\nCyLCFcd288n+jDHhqUGtktznF+5Q1ctqlqnqJuBv/gos5G2a7RQj+ag1UlFZJa/9sJUzBnegU0qs\nT/ZpjAlPDbpjUNUqoJs96exDK2qKkU72ye7eWZRJQWmlNVE1xjSZN11ibAS+E5H3gaKahar6kM+j\nCnVVFW4x0hk+KUaqrlZe+G4zw7qkMLKrtSA2xjSNN4lhg/tqBST6J5wwsXE2lO7zWWuk2Wtz2Li7\niEcuHW5NVI0xTebNk8/3+jOQsLLyXWid6LNipOe/20T7pGgmDrHWw8aYpmtwYnA7zfsNMAiIqVmu\nqr45u4WLqgpY/ZFTjBQVc+TPH8HaXQX8b91ubju9H1E25oIxxge8OZO8CqwGegD3ApuB+X6IKbRt\nmg0le33WGumF7zYTHdmKyWNszAVjjG94kxjaqOq/gQpVna2q1wB2t+CtFe+5xUinNHlX2fmlvLs4\nkwtGdiYt3hqMGWN8w5vK5wr3PUtEzgR2AGm+DymE7W+NNMEnxUj/+HwtVdXK9Sf28kFwxhjj8CYx\n/ElEkoFbgEeBJOBXfokqVNUUI/mgNdKKHXm8sXAbPz2hB93T430QnDHGOBpclKSqH6pqnqouV9Xx\nqjpKVd8/0nYiMkFE1ojIehG5vY71vxaRlSKyVES+EpHQ7c9hxXvQOgF6N60YSVX504erSImN4ucn\n9/FRcMYY4/BmPIaeIvKBiOwWkWwRmSEiPY+wTQTwOHAGMBCYLCIDD/rYYmC0qg4F3gL+7t0hBIma\nvpH6ToCopnVZ8cXKXczZmMuvTutLcqz1Y2iM8S1vKp+nA28AHYBOwJvAa0fYZgywXlU3qmo58Dpw\nrucHVHWmqha7s3OB0Owvesl0pxhp+OQm7aa8spq/frKa3u0SmGItkYwxfuBNYohT1ZdVtdJ9vYLH\n8wz16Axs85jPdJfV51rgk7pWiMg0EVkgIgtycnK8CLsFqKqA/z0EnUY0uTXSy3O3sGl3EXdMHECk\nPbdgjPEDb84sn4jI7SLSXUS6ichvgI9FJE1Emtw6SUSmAqOBB+par6rPqOpoVR3dtm3bpn5d81r2\nJuzbAif+BprQZcXeonIe+XItY/ukM65fkP0bGGOChjetkia579cD6k4LcKk7X1d9w3acIUBrZLjL\nahGRU4E7gJNUtcyLmFq+6ir43z+g/RDnaecmeOSrdRSWVXLnmQOtTyRjjN94c8fwW2CYqvYAXgCW\nABeqag9Vra8Sej7QR0R6uF12XwrUaskkIiNwxpA+R1WzvT6Clm7Fu5C7Hk68tUl3C+uzC3l57hYm\nj+lKvw7Wh6Exxn+8SQx3qmq+iJyA88Tzc8CTh9vAHSP658BnwCrgDVVdISL3icg57sceABKAN0Xk\nR7db79BQXQ3fPAht+8OAc478+cP468eriIuK4Fen9fVRcMYYUzdvipKq3PczgWdV9SMR+dORNlLV\nj4GPD1p2t8f0qV7EEFxWfwA5q+CC56BV4yuKv123m69WZ3P7Gf1JT/DNMKDGGFMfb85W20XkaeAS\nnErnaC+3Dy+q8M0DkNYLBl/Q6N1UVSt/+mglXdJiueq47r6Lzxhj6uHNiX0STpHQ6aq6D6efpNv8\nElUoWPsp7FwGY2+BVhGN3s0bC7axemcBt08YQExU4/djjDEN5c1APcXAOx7zWUCWP4IKeqow+++Q\n0hWGTjry5+tRUFrBPz5fw1HdU5k4pIMPAzTGmPpZUZA/bPgKdiyCE34NEY3vsuKJWRvYXVhuzVON\nMc3KEoOvqcLsByCpMwyf0ujdbNtTzL+/3cT5IzozrEuKDwM0xpjDs8Tga5v/B9vmwvE3Q2TjWxD9\n7dPVtBL4zYR+PgzOGGOOzBKDr83+OyS0h5GXN3oXC7fs4cOlWUw7sRcdk5vWE6sxxnjLEoMvbZ3r\n3DEc98tGd629aXcRP3tlER2TY7j+xMP2am6MMX5hicGXZv8d4trA6Ksbtfm2PcVMeXYuldXKi9eM\nIT7am+cPjTHGNywx+ErmQqc10rE/h9beD7W5Y18Jk5+dS3F5Fa9cezR921t/SMaYwLDE4CvfPAAx\nKTDmOq83zc4vZcqzc8krruDla8cwsFOSHwI0xpiGscTgC1lLYe0ncMwNEO3dlf7uwjKmPDeP7IIy\n/nPNGIZmWNNUY0xgWWLwhW8egOgkOPp6rzbbW1TO1Ofmkbm3mOevOopR3VL9FKAxxjScJYamyl4F\nq96HMdMgtuFX+3klFVzx/A9s3F3Ec1ccxTE92/gxSGOMaThLDE1RVggzboTWCU4xUgMVllVy1Qs/\nsHpnPk9PHcUJfdL9GKQxxnjH2kM2VmU5vHEF7FgMk16G+IZd8ReXV3LNC/NZmpnHE5eNZHz/dn4O\n1BhjvGN3DI1RXQ0zbnCap579CAw4q0GblVZU8dMXF7Bgyx4evmQ4pw+yHlONMS2PJQZvqcJnv4dl\nb8Ipd8PIKxq0WXZBKde9tIA5G3N58OJhnD2sk58DNcaYxrGiJG99+xDMe9KpUzjh10f8eFllFc9/\nu5nHvl5HeVU1918whAtGZjRDoMYY0ziWGLyx8EX46j4YMgl+8mc4zBgJqspnK3bxl49XsXVPMacO\naM8dZw6gR7r3T0UbY0xzssTQUKs+hA9vht6nwrmPQ6v6S+FWZeVz3wcrmbMxl77tE3jl2qOt5ZEx\nJmhYYmiIzd/CW9dAp5Ew6SWIbF3nx3ILy/jHF2t5/YetJMdG8cdzBzF5TFciI6wqxxgTPCwxHMnO\nZfDaZEjtDpe9WWcHeeWV1bw0ZzOPfLWOkvIqrjyuOzef0pfkuMYP62mMMYFiieFw9myCVy50+j+6\n/B2ISwOc+oOcgjJWZuWzKquANxdsY+PuIsb1a8udZw6kd7uEAAdujDGNZ4mhPoXZ8PL5aFU5GydO\nZ8kGWJW1klVZBazKyie3qHz/R/t3SOSFq49ifD97WM0YE/zCKzHMfw5WzgCgWqGyupqKKqWyyn33\nmE8qySS+ch+XV97B/Jd2AbtoHdmKvu0TOLl/OwZ0THJfiaTE1V3nYIwxwSisEsP/1uwiaUsOldVK\nVbXW+7kIEfZEtOXLdr9mZI+TmOomgZ7p8VaRbIwJeWGVGHYNuJK3IieSGteatPjWpMa3JjUuirQ4\nZzotvjUpcVFER0YAMCrA8RpjTCCEVWK4aFQGF42yp46NMeZwrFzEGGNMLZYYjDHG1GKJwRhjTC2W\nGIwxxtRiicEYY0wtlhiMMcbUYonBGGNMLZYYjDHG1CKq9XcN0VKJSA6wpZGbpwO7fRhOSxBqxxRq\nxwOhd0yhdjwQesdU1/F0U9W2R9owKBNDU4jIAlUdHeg4fCnUjinUjgdC75hC7Xgg9I6pKcdjRUnG\nGGNqscRgjDGmlnBMDM8EOgA/CLVjCrXjgdA7plA7Hgi9Y2r08YRdHYMxxpjDC8c7BmOMMYdhicEY\nY0wtYZUYRGSCiKwRkfUicnug42kqEdksIstE5EcRWRDoeBpDRJ4XkWwRWe6xLE1EvhCRde57aiBj\n9EY9x3OPiGx3f6cfRWRiIGP0loh0EZGZIrJSRFaIyE3u8qD8nQ5zPEH7O4lIjIj8ICJL3GO6113e\nQ0Tmuee8/4pIgwaoD5s6BhGJANYCpwGZwHxgsqquDGhgTSAim4HRqhq0D+WIyIlAIfCSqg52l/0d\n2KOq97sJPFVVfxvIOBuqnuO5ByhU1QcDGVtjiUhHoKOqLhKRRGAhcB5wFUH4Ox3meCYRpL+TiAgQ\nr6qFIhIFfAvcBPwaeEdVXxeRp4AlqvrkkfYXTncMY4D1qrpRVcuB14FzAxxT2FPVb4A9By0+F3jR\nnX4R5482KNRzPEFNVbNUdZE7XQCsAjoTpL/TYY4naKmj0J2Ncl8KnAy85S5v8G8UTomhM7DNYz6T\nIP/PgPPDfy4iC0VkWqCD8aH2qprlTu8E2gcyGB/5uYgsdYuagqLIpS4i0h0YAcwjBH6ng44Hgvh3\nEpEIEfkRyAa+ADYA+1S10v1Ig8954ZQYQtEJqjoSOAO40S3GCCnqlHUGe3nnk0AvYDiQBfwjsOE0\njogkAG8DN6tqvue6YPyd6jieoP6dVLVKVYcDGTglJP0bu69wSgzbgS4e8xnusqClqtvd92zgXZz/\nDKFgl1sOXFMenB3geJpEVXe5f7TVwLME4e/kllu/Dbyqqu+4i4P2d6rreELhdwJQ1X3ATOBYIEVE\nIt1VDT7nhVNimA/0cWvpWwOXAu8HOKZGE5F4t+IMEYkHfgIsP/xWQeN94Ep3+kpgRgBjabKak6fr\nfILsd3IrNv8NrFLVhzxWBeXvVN/xBPPvJCJtRSTFnY7FaWSzCidBXOR+rMG/Udi0SgJwm589DEQA\nz6vqnwMcUqOJSE+cuwSASGB6MB6PiLwGjMPpIngX8AfgPeANoCtO9+qTVDUoKnTrOZ5xOMUTCmwG\nrvcom2/xROQE4H/AMqDaXfx7nHL5oPudDnM8kwnS30lEhuJULkfgXPC/oar3ueeJ14E0YDEwVVXL\njri/cEoMxhhjjiycipKMMcY0gCUGY4wxtVhiMMYYU4slBmOMMbVYYjDGGFOLJQZjmpmIjBORDwMd\nhzH1scRgjDGmFksMxtRDRKa6fdz/KCJPu52UFYrIP90+778SkbbuZ4eLyFy3A7Z3azpgE5HeIvKl\n20/+IhHp5e4+QUTeEpHVIvKq+zSuMS2CJQZj6iAiA4BLgOPdjsmqgMuAeGCBqg4CZuM82QzwEvBb\nVR2K80RtzfJXgcdVdRhwHE7nbOD06HkzMBDoCRzv94MypoEij/wRY8LSKcAoYL57MR+L00lcNfBf\n9zOvAO+ISDKQoqqz3eUvAm+6fVl1VtV3AVS1FMDd3w+qmunO/wh0xxlcxZiAs8RgTN0EeFFVf1dr\nochdB32usX3KePZXU4X9LZoWxIqSjKnbV8BFItIO9o9v3A3nb6amt8opwLeqmgfsFZGx7vLLgdnu\n6GCZInKeu49oEYlr1qMwphHsKsWYOqjqShG5E2eEvFZABXAjUASMcddl49RDgNOl8VPuiX8jcLW7\n/HLgaRG5z93Hxc14GMY0ivWuaowXRKRQVRMCHYcx/mRFScYYY2qxOwZjjDG12B2DMcaYWiwxGGOM\nqcUSgzHGmFosMRhjjKnFEoMxxpha/h8LuZzuEHuHpQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6ZR0kc7X-tm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "de2fab19-023b-464f-9952-d670cd7de5b5"
      },
      "source": [
        "short = x_val[0:100]\n",
        "\n",
        "if True:\n",
        "#with tf.Session() as session:\n",
        "#  K.set_session(session)\n",
        "#  session.run(tf.global_variables_initializer())\n",
        "#  session.run(tf.tables_initializer())\n",
        "  #model.load_weights('./model.h5')  \n",
        "  eval = model.evaluate(x_val, y_val)\n",
        "  print('model.evaluate on val holdout: ' ,model.metrics_names, eval)\n",
        "  print('history: ', history)\n",
        "  predicts = model.predict(short, batch_size=32)\n",
        "  print('shape: {}'.format(predicts.shape))\n",
        "\n",
        "print(len(predicts[0]))\n",
        "print(len(predicts[0][0]))\n",
        "#print(predicts[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11025/11025 [==============================] - 20s 2ms/step\n",
            "model.evaluate on val holdout:  ['loss', 'sparse', 'sequence'] [0.4464581141342111, 0.9574503398320031, 0.03637188208684359]\n",
            "history:  <keras.callbacks.History object at 0x7f64fe4ada90>\n",
            "shape: (100, 100, 20000)\n",
            "100\n",
            "20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFy2tfyIYOtY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5091c911-ae69-4672-92c4-cb3e1efe9117"
      },
      "source": [
        "def maxindx(pred):\n",
        "    maxi=-1\n",
        "    maxv=-1.0\n",
        "    for x in range(len(pred)):\n",
        "        if pred[x] > maxv:\n",
        "            maxv = pred[x]\n",
        "            maxi = x\n",
        "    return (maxi, maxv)\n",
        "\n",
        "def match(data, prediction):\n",
        "    good = 0\n",
        "    total = 0\n",
        "    for i in range(len(data)):\n",
        "        if data[i] == np.argmax(prediction[i]):\n",
        "            good += 1\n",
        "        total += 1\n",
        "    #print('{}, {}'.format(good, total))\n",
        "    if (total == 0):\n",
        "        return 0\n",
        "    return good / total\n",
        "\n",
        "parallel = 0.0\n",
        "serial = 0.0\n",
        "total = 0\n",
        "for n in range(len(short)):\n",
        "    #print(short[n][0:5])\n",
        "    check = match(short[n], predicts[n])\n",
        "    parallel += check\n",
        "    if check > 0.9999:\n",
        "        serial += 1\n",
        "    total += 1\n",
        "\n",
        "print('Parallel, serial: ', parallel / total, serial / total)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parallel, serial:  0.9543999999999998 0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNWVxMyKd3P8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}