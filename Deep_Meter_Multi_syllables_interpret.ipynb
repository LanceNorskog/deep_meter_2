{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Meter_Multi_syllables_interpret.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "co7MV6sX7Xto"
      },
      "cell_type": "markdown",
      "source": [
        "# [Keras + Universal Sentence Encoder = Deep Meter] (https://www.dlology.com/blog/keras-meets-universal-sentence-encoder-transfer-learning-for-text-data/) "
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eAVQGidpL8v5"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook creates an autoencoder using the Universal Sentence Encoder. The autoencoder output is CMUdict syllables. The dataset is that subset of Allison Parrish's Project Gutenberg poetry archive which happens to scan in iambic pentameter.\n",
        "\n",
        "The notebook is based on Chengwei Zhang's example of wrapping the USE inside a larger tensorflow model saves to a Keras model (without save the USE itself in the TF model).\n",
        "\n",
        "The Universal Sentence Encoder makes getting sentence level embeddings as easy as it has historically been to lookup the embeddings for individual words. The sentence embeddings can then be trivially used to compute sentence level meaning similarity as well as to enable better performance on downstream classification tasks using less supervised training data.\n",
        "\n",
        "Since there are 10 one-hot values for 10 sets of 6k syllables, this is \"multi-label classification\"\n",
        "Changes for multi-label classification:\n",
        "sigmoid activation instead of softmax\n",
        "binary_crossentropy\n",
        "\n",
        "Text format is tab-separated, 2 columns: first text, second multi-level\n",
        "array of syllables:\n",
        "\n",
        "Multi-output version"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pOTzp8O36CyQ"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting Started\n",
        "\n",
        "This section sets up the environment for access to the Universal Sentence Encoder on TF Hub and provides examples of applying the encoder to words, sentences, and paragraphs."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lVjNK8shFKOC",
        "outputId": "4c7ec6e2-9e55-41d3-d04f-50a026446932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the latest Tensorflow version.\n",
        "!pip3 install --quiet \"tensorflow>=1.7\"\n",
        "# Install TF-Hub.\n",
        "!pip3 install --quiet tensorflow-hub\n",
        "!pip3 install pygtrie\n",
        "#%cd /content\n",
        "!git clone https://github.com/LanceNorskog/deep_meter || true\n",
        "%cd /content/deep_meter\n",
        "!git pull\n",
        "# could not figure out how to read gzipped files as text!\n",
        "!gunzip -qf blobs/*.gz || true\n",
        "!gunzip -qf prepped_data/*.gz || true"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygtrie\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/42/f70a09ce102fa2fc1c54df26f71ecbf0a38e78c1da0b1b58bcf539cf2e94/pygtrie-2.3.tar.gz\n",
            "Building wheels for collected packages: pygtrie\n",
            "  Running setup.py bdist_wheel for pygtrie ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3c/d0/b1/c8f2bbb9dc1fd0e25acde4d81972055b426430630f99395b8d\n",
            "Successfully built pygtrie\n",
            "Installing collected packages: pygtrie\n",
            "Successfully installed pygtrie-2.3\n",
            "Cloning into 'deep_meter'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Counting objects: 100% (127/127), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 370 (delta 67), reused 91 (delta 34), pack-reused 243\u001b[K\n",
            "Receiving objects: 100% (370/370), 24.37 MiB | 19.72 MiB/s, done.\n",
            "Resolving deltas: 100% (198/198), done.\n",
            "/content/deep_meter\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MSeY-MUQo2Ha",
        "outputId": "101b6734-5172-49b4-cc7b-86f3dac2caa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "import pickle\n",
        "np.random.seed(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "feBc_8Y-pt6F",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# github deep_meter code\n",
        "import utils\n",
        "# should not need this to use utils.flatten but is true anyway?\n",
        "from itertools import chain, product\n",
        "import subprocess\n",
        "import syllables\n",
        "import decodesyllables\n",
        "import cmudict\n",
        "# misc for this notebook\n",
        "from ast import literal_eval\n",
        "\n",
        "import scipy\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2WmnhjxDvTWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "dd039c80-a707-441e-b1ab-676b2a9d8ada"
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FwAQNy1eMDkQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# read classified poetry lines: text tab [['syll', 'la', 'ble'], ...]\n",
        "# clip to only most common syllables with syllable manager\n",
        "# ['words', ...], [[[0,0,1,0], ...]]\n",
        "def get_data(filename, syll_mgr, num_symbols, max_lines=55000):\n",
        "    num_syllables = syll_mgr.get_size()      \n",
        "    lines = open(filename, 'r').read().splitlines()\n",
        "    num_lines = min(max_lines, len(lines))\n",
        "    text_lines = []\n",
        "    text_sylls = []\n",
        "    for i in range(0, len(lines)):\n",
        "      if i == num_lines:\n",
        "        break\n",
        "      parts = lines[i].split(\"\\t\")\n",
        "      label = utils.flatten(literal_eval(parts[1]))\n",
        "      if len(label) == num_symbols:\n",
        "        text_lines.append(str(parts[0]))\n",
        "        text_sylls.append(label)\n",
        "    num_lines = len(text_lines)\n",
        "    label_array = np.zeros((num_symbols, num_lines, num_syllables), dtype=np.int8)\n",
        "    for i in range(0, num_lines):\n",
        "      for j in range(num_symbols):\n",
        "        label_array[j][i][syll_mgr.get_encoding(text_sylls[i][j])] = 1\n",
        "\n",
        "    return (text_lines, label_array)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3HAtd4X5DayF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# syllables in descending order of occurrence - 6k in gutenberg.iambic_pentameter, 15k total\n",
        "# clamp to most common 100 syllables while debugging- use NCE to get all syllables or interesting number\n",
        "# 98 + pause + wildcard\n",
        "# iambic pentameter\n",
        "num_symbols = 10\n",
        "#syll_mgr = syllables.syllables(num_syllables)\n",
        "syll_mgr = syllables.syllables()\n",
        "num_syllables = syll_mgr.get_size() \n",
        "syll_weights = {}\n",
        "counts = syll_mgr.get_counts()\n",
        "maxim = np.max(counts)\n",
        "for i in range(len(counts)):\n",
        "  if counts[i] > 0:\n",
        "    syll_weights[i] = 1/(counts[i]/maxim)\n",
        "  else:\n",
        "    syll_weights[i] = 0\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eN9aqig-QpDZ",
        "outputId": "5ac17ad6-8792-4afb-822d-59ea9952c2b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "(train_text, train_label) = get_data('prepped_data/gutenberg.iambic_pentameter.train', syll_mgr, num_symbols)\n",
        "num_training = len(train_text)\n",
        "#train_text = train_text[0:100]\n",
        "#train_label = train_label[0:100]\n",
        "\n",
        "(test_text, test_label) = get_data('prepped_data/gutenberg.iambic_pentameter.test', syll_mgr, num_symbols)\n",
        "#test_text = test_text[0:100]\n",
        "#test_label = test_label[0:100]\n",
        "\n",
        "num_testing = len(test_text)\n",
        "print(len(train_text))\n",
        "print(len(test_text))\n",
        "print(train_label.shape)\n",
        "print(test_label.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51638\n",
            "4200\n",
            "(10, 51638, 6635)\n",
            "(10, 4200, 6635)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bqcRy_JWXe0u"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Keras model and save weights\n",
        "This only trains and save our Keras layers not the embed module' weights."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "nQux6qLdXabG"
      },
      "cell_type": "markdown",
      "source": [
        "## Make predictions"
      ]
    },
    {
      "metadata": {
        "id": "t3m7j_t1y8Wv",
        "colab_type": "code",
        "outputId": "dff5764b-08e2-4769-e612-b8d3a8303713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# load pre-saved predictions\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/predictions_syllables.pkl ./predictions_syllables.pkl \n",
        "with open(\"./predictions_syllables.pkl\", \"rb\") as f:\n",
        "    predicts = pickle.load(f)\n",
        "print(\"Number of predictions: \" + str(len(predicts[0])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of predictions: 4200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xaR0d5VPU23Z",
        "outputId": "4fb53f86-aad1-4b3b-e8cd-adcb362cf263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "max_variants = 5\n",
        "num_tests = len(predicts[0])\n",
        "num_tests = min(5, len(predicts[0]))\n",
        "# Collect possible syllables from each output model\n",
        "# [num_lines][num_symbols][N > 0.8]\n",
        "index_arrays = [[]] * num_tests\n",
        "for j in range(num_tests):\n",
        "    index_arrays[j] = [[]] * num_symbols\n",
        "    for i in range(num_symbols):\n",
        "      index_arrays[j][i] = []\n",
        "      \n",
        "# index into each possible syllable and score\n",
        "for i in range(num_symbols):\n",
        "  for j in range(num_tests):\n",
        "    for k in range(num_syllables):\n",
        "      if predicts[i][j][k] > 0.05:\n",
        "        #print(\"i, j {0},{1}, -> {2}\".format(i,j,k))\n",
        "        index_arrays[j][i].append(k)\n",
        "        \n",
        "# sort order of possible syllables at each slot by score\n",
        "for j in range(num_tests):\n",
        "  indexes = index_arrays[j]\n",
        "  for i in range(num_symbols):\n",
        "    score_set = [1.0] * len(indexes[i])\n",
        "    for k in range(len(indexes[i])):\n",
        "      score_set[k] = predicts[i][j][k]\n",
        "    new_indexes = []\n",
        "    sorted_i = list(np.argsort(score_set))\n",
        "    sorted_i.reverse()\n",
        "    for x in sorted_i:\n",
        "      new_indexes.append(indexes[i][x])\n",
        "    index_arrays[j][i] = new_indexes[0:max_variants]\n",
        "for j in range(min(num_tests,30)):\n",
        "  print(index_arrays[j])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[11, 6, 9, 7, 2], [], [5, 3, 2], [3], [9, 2, 3], [3], [9, 3, 2], [54, 3], [9, 5, 3, 2], [563, 633, 269, 222]]\n",
            "[[6, 2, 3], [175, 208], [10, 22, 8, 2], [79, 95], [29, 2, 3], [208, 79], [10, 19, 3, 2], [208], [6, 13, 223, 19, 3], [79, 73, 3237]]\n",
            "[[5], [43], [5, 3, 2], [], [2, 3], [3], [4, 3, 2], [5, 3], [5, 3, 2], [545]]\n",
            "[[27, 2, 6], [27], [51, 31, 25], [], [4, 53, 2, 3], [], [31, 51, 4, 2], [], [13, 25, 21, 4, 2], [99]]\n",
            "[[51, 2, 3], [6], [4, 3, 2], [], [2, 3], [], [3, 2], [], [6, 13, 4, 2], [173]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kcjSndW8KX0d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "7fcf94f7-1a33-4b97-9f37-cacfc739a44b"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "decoder = decodesyllables.Decoder(cmudict.CMUDict())\n",
        "for j in range(0,num_tests):\n",
        "  print(\"Predicting sentence: \" + test_text[j])\n",
        "  score_array = []\n",
        "  for index_list in product(*index_arrays[j]):\n",
        "    index_list = list(index_list)\n",
        "    score_set = [1.0] * num_symbols\n",
        "    score_array.append(score_set)\n",
        "    for i in range(num_symbols):\n",
        "      for k in range(num_syllables):\n",
        "        score_set[i] = predicts[i][j][index_list[i]]\n",
        "        \n",
        "  # product() generates empty list if any slot is empty\n",
        "  if len(score_array) == 0:\n",
        "    print(\"  no interpretations found\")\n",
        "    continue\n",
        "\n",
        "  syll_array = []\n",
        "  for index_list in product(*index_arrays[j]):\n",
        "    index_list = list(index_list)\n",
        "    syll_set = [''] * num_symbols\n",
        "    syll_array.append(syll_set)\n",
        "    for i in range(num_symbols):\n",
        "      for k in range(num_syllables):\n",
        "        syll_set[i] = syll_mgr.get_syllable(index_list[i])\n",
        "\n",
        "  syll_test = syll_array[topindexes[0]]\n",
        "\n",
        "  print(syll_test)\n",
        "  count = 0\n",
        "  for s in decoder.decode_sentence(syll_test):\n",
        "    count += 1\n",
        "    print(s)\n",
        "  if count == 0:\n",
        "    print(\"Sentences found: \".format(count))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting sentence: To life, the creamy onyx and the skins\n",
            "  no interpretations found\n",
            "Predicting sentence: And what is Man the while? And what his will?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yyDGVtigW57f",
        "outputId": "9dfd2224-ec00-4c32-ca8f-03c0bc701bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "cell_type": "code",
      "source": [
        "categories = df_train.label.cat.categories.tolist()\n",
        "predict_logits = predicts.argmax(axis=1)\n",
        "print(\"Categorie: {0}\".format(categories))\n",
        "predict_labels = [categories[logit] for logit in predict_logits]\n",
        "predict_labels"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7f6e6bf5580f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredict_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Categorie: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredict_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlogit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredict_logits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hYhmukbSKpnp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "os.remove('./model_syllables.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pbH87mEcOKgA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.remove('./predictions_syllables.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}