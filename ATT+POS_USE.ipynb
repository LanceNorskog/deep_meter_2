{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ATT+POS USE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYd5dVdmTaK8",
        "colab_type": "code",
        "outputId": "98f51b69-2b4a-4ab3-8afb-d12f8e6015a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "!pip install tensorflow-hub\n",
        "!pip install numpy==1.16.1\n",
        "#!pip install keras==2.1.2\n",
        "!pip install git+https://github.com/LanceNorskog/deep_meter_2#egg=deepmeter\n",
        "#!pip install sortedcontainer\n",
        "\n",
        "from __future__ import print_function\n",
        "import math\n",
        "import pickle\n",
        "import json\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Model, Sequential\n",
        "from keras import layers \n",
        "from keras import metrics\n",
        "from keras.datasets import reuters\n",
        "from keras.preprocessing import text\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from cmu.syllables_cmu import syllables as word2sylls\n",
        "print(word2sylls['therefore'])\n",
        "\n",
        "# cut texts after this number of words\n",
        "# (among top max_features most common words)\n",
        "max_features = 16000\n",
        "# longest output sentence\n",
        "maxlen = 5\n",
        "batch_size = 32\n",
        "\n",
        "!wget -nc https://raw.githubusercontent.com/LanceNorskog/deep_meter_2/master/haiku_5_same.txt\n",
        "haiku_data = 'haiku_5_same.txt'\n",
        "haiku_text = []\n",
        "with open(haiku_data) as f:\n",
        "    for line in f.readlines():\n",
        "        haiku_text.append(line.split('\\t')[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (3.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.16.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub) (41.0.1)\n",
            "Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.6/dist-packages (1.16.1)\n",
            "Requirement already satisfied: deepmeter from git+https://github.com/LanceNorskog/deep_meter_2#egg=deepmeter in /usr/local/lib/python3.6/dist-packages (0.0.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['DH EH R', 'F AO R']\n",
            "File ‘haiku_5_same.txt’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPpSGpck_JAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer_from_json(json_string):\n",
        "    \"\"\"Parses a JSON tokenizer configuration file and returns a\n",
        "    tokenizer instance.\n",
        "    # Arguments\n",
        "        json_string: JSON string encoding a tokenizer configuration.\n",
        "    # Returns\n",
        "        A Keras Tokenizer instance\n",
        "    \"\"\"\n",
        "    tokenizer_config = json.loads(json_string)\n",
        "    config = tokenizer_config.get('config')\n",
        "\n",
        "    word_counts = json.loads(config.pop('word_counts'))\n",
        "    word_docs = json.loads(config.pop('word_docs'))\n",
        "    index_docs = json.loads(config.pop('index_docs'))\n",
        "    # Integer indexing gets converted to strings with json.dumps()\n",
        "    index_docs = {int(k): v for k, v in index_docs.items()}\n",
        "    index_word = json.loads(config.pop('index_word'))\n",
        "    index_word = {int(k): v for k, v in index_word.items()}\n",
        "    word_index = json.loads(config.pop('word_index'))\n",
        "\n",
        "    tokenizer = text.Tokenizer(**config)\n",
        "    tokenizer.word_counts = word_counts\n",
        "    tokenizer.word_docs = word_docs\n",
        "    tokenizer.index_docs = index_docs\n",
        "    tokenizer.word_index = word_index\n",
        "    tokenizer.index_word = index_word\n",
        "\n",
        "    return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JSlaFFPiT5w",
        "colab_type": "code",
        "outputId": "f2aaa9ec-0cb9-47bc-b391-25dfe2d12420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!date\n",
        "!wget -nc https://raw.githubusercontent.com/LanceNorskog/deep_meter_2/master/haiku_5_same.txt\n",
        "!wget -nc https://raw.githubusercontent.com/LanceNorskog/deep_meter_2/master/toki_cmu.json\n",
        "haiku_data = 'haiku_5_same.txt'\n",
        "toki_file = 'toki_cmu.json'\n",
        "haiku_text = []\n",
        "with open(haiku_data) as f:\n",
        "    for line in f.readlines():\n",
        "        haiku_text.append(line.split('\\t')[0])\n",
        "!date\n",
        "big_sylls = set()\n",
        "for index, word in enumerate(word2sylls):\n",
        "    sylls = word2sylls[word]\n",
        "    for syll in sylls:\n",
        "        syll = syll.replace(' ', '').lower()\n",
        "        big_sylls.add(syll)\n",
        "\n",
        "syll2idx = {}\n",
        "for index, syll in enumerate(big_sylls):\n",
        "    syll2idx[syll] = index\n",
        "idx2syll = [0] * len(syll2idx)\n",
        "for index, syll in enumerate(syll2idx):\n",
        "    idx2syll[index] = syll\n",
        "\n",
        "print(syll2idx['dhehr'], idx2syll[1])\n",
        "print('# features: ', len(idx2syll))\n",
        "!date\n",
        "data_all = np.zeros((len(haiku_text), 5), dtype='int32')\n",
        "for i in range(len(haiku_text)):    \n",
        "    seq = text.text_to_word_sequence(haiku_text[i])\n",
        "    sylls = []\n",
        "    for word in seq:\n",
        "        if word in word2sylls:\n",
        "            for syll in word2sylls[word]:\n",
        "                sylls.append(syll.replace(' ', '').lower())\n",
        "    \n",
        "    for j in range(5):\n",
        "        if len(sylls) > j:\n",
        "            data_all[i][j] = syll2idx[sylls[j]]\n",
        "    if i == 0:\n",
        "        print(haiku_text[i])\n",
        "        print(sylls)\n",
        "        print(data_all[i])\n",
        "\n",
        "!date   \n",
        "print(haiku_text[0])\n",
        "print(data_all[0])\n",
        "print(haiku_text[2999])\n",
        "print(data_all[2999])\n",
        "!date\n",
        "#(x_train, x_test, y_train, y_test) = train_test_split(haiku_text, data_all)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jun 27 21:56:32 UTC 2019\n",
            "File ‘haiku_5_same.txt’ already there; not retrieving.\n",
            "\n",
            "File ‘toki_cmu.json’ already there; not retrieving.\n",
            "\n",
            "Thu Jun 27 21:56:35 UTC 2019\n",
            "12668 aemk\n",
            "# features:  15086\n",
            "Thu Jun 27 21:56:36 UTC 2019\n",
            "a abandon church\n",
            "['ah', 'ah', 'baen', 'dahn', 'cherch']\n",
            "[6763 6763 9255  124 7555]\n",
            "Thu Jun 27 21:56:39 UTC 2019\n",
            "a abandon church\n",
            "[6763 6763 9255  124 7555]\n",
            "a cardboard cutout\n",
            "[ 6763 14984  5325  6329 11795]\n",
            "Thu Jun 27 21:56:40 UTC 2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbXnnIliX2td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
        "embed = hub.Module(module_url)\n",
        "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value\n",
        "def UniversalEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6ffyQDaP4ot",
        "colab_type": "code",
        "outputId": "4d8ab10a-3f38-406c-c2f6-67031d7e1404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "(x_train, x_test, y_train, y_test) = train_test_split(haiku_text, data_all)\n",
        "print(x_train[0], y_train[0])\n",
        "print(x_test[0], y_test[0])\n",
        "print(x_train[-1], y_train[-1])\n",
        "print(x_test[-1], y_test[-1])\n",
        "\n",
        "def get_lstm(size, return_sequences=True):\n",
        "    return layers.CuDNNLSTM(size, return_sequences=return_sequences)\n",
        "\n",
        "def pack(indexes, maxlen):\n",
        "    print(type(indexes))\n",
        "    print(type(indexes[0]))\n",
        "    print(type(indexes[0][0]))\n",
        "    ilen = len(indexes)\n",
        "    out = np.zeros((ilen, maxlen))\n",
        "    for i in range(ilen):\n",
        "        for j in range(len(indexes[i])):\n",
        "            if j >= maxlen:\n",
        "                continue\n",
        "            #print(i,j, len(indexes[i]))  \n",
        "            if len(indexes[i][j]) > 0:\n",
        "                out[i][j] = indexes[i][j][0]\n",
        "    return out\n",
        "    \n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "#y_train = np.expand_dims(pack(y_train, maxlen), -1)\n",
        "#y_test = np.expand_dims(pack(y_test, maxlen), -1)\n",
        "y_train = np.expand_dims(y_train, -1)\n",
        "y_test = np.expand_dims(y_test, -1)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)\n",
        "print(y_test[0][0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dressed in a blue gown [ 5305  5219  6763  2284 10067]\n",
            "island counter top [ 5569  4746 13831 13197 11062]\n",
            "toilet paper rolls [ 8802  8122  5662  5108 14488]\n",
            "perform in the race [ 5108 13645  5219 10473  6511]\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (71716,)\n",
            "x_test shape: (23906,)\n",
            "y_train shape: (71716, 5, 1)\n",
            "y_test shape: (23906, 5, 1)\n",
            "[5569]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YyrrjKwTDhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/philipperemy/keras-snail-attention/blob/master/attention.py\n",
        "class AttentionBlock(layers.Layer):\n",
        "\n",
        "    def __init__(self, dims, k_size, v_size, seq_len=None, **kwargs):\n",
        "        self.k_size = k_size\n",
        "        self.seq_len = seq_len\n",
        "        self.v_size = v_size\n",
        "        self.dims = dims\n",
        "        self.sqrt_k = math.sqrt(k_size)\n",
        "        self.keys_fc = None\n",
        "        self.queries_fc = None\n",
        "        self.values_fc = None\n",
        "        super(AttentionBlock, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # https://stackoverflow.com/questions/54194724/how-to-use-keras-layers-in-custom-keras-layer\n",
        "        self.keys_fc = layers.Dense(self.k_size)\n",
        "        self.keys_fc.build((None, self.dims))\n",
        "        self._trainable_weights.extend(self.keys_fc.trainable_weights)\n",
        "\n",
        "        self.queries_fc = layers.Dense(self.k_size)\n",
        "        self.queries_fc.build((None, self.dims))\n",
        "        self._trainable_weights.extend(self.queries_fc.trainable_weights)\n",
        "\n",
        "        self.values_fc = layers.Dense(self.v_size)\n",
        "        self.values_fc.build((None, self.dims))\n",
        "        self._trainable_weights.extend(self.values_fc.trainable_weights)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        # check that the implementation matches exactly py torch.\n",
        "        keys = self.keys_fc(inputs)\n",
        "        queries = self.queries_fc(inputs)\n",
        "        values = self.values_fc(inputs)\n",
        "        logits = K.batch_dot(queries, K.permute_dimensions(keys, (0, 2, 1)))\n",
        "        mask = K.ones_like(logits) * np.triu((-np.inf) * np.ones(logits.shape.as_list()[1:]), k=1)\n",
        "        logits = mask + logits\n",
        "        probs = layers.Softmax(axis=-1)(logits / self.sqrt_k)\n",
        "        read = K.batch_dot(probs, values)\n",
        "        output = K.concatenate([inputs, read], axis=-1)\n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_shape = list(input_shape)\n",
        "        output_shape[-1] += self.v_size\n",
        "        return tuple(output_shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWdU04vHTE61",
        "colab_type": "code",
        "outputId": "89f0809e-3569-4c86-a85d-863ca3a0e06d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def sparse_categorical_accuracy(y_true, y_pred):\n",
        "    # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n",
        "    if K.ndim(y_true) == K.ndim(y_pred):\n",
        "        y_true = K.squeeze(y_true, -1)\n",
        "    # convert dense predictions to labels\n",
        "    y_pred_labels = K.argmax(y_pred, axis=-1)\n",
        "    y_pred_labels = K.cast(y_pred_labels, K.floatx())\n",
        "    return K.cast(K.equal(y_true, y_pred_labels), K.floatx())\n",
        "\n",
        "def sparse_categorical_accuracy_per_sequence(y_true, y_pred):\n",
        "    # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n",
        "    if K.ndim(y_true) == K.ndim(y_pred):\n",
        "        y_true = K.squeeze(y_true, -1)\n",
        "    # convert dense predictions to labels\n",
        "    y_pred_labels = K.argmax(y_pred, axis=-1)\n",
        "    y_pred_labels = K.cast(y_pred_labels, K.floatx())\n",
        "    return K.min(K.cast(K.equal(y_true, y_pred_labels), K.floatx()), axis=-1)\n",
        "\n",
        "def sparse_temporal_top_k_categorical_accuracy(y_true, y_pred, k=5):\n",
        "    original_shape = K.shape(y_true)\n",
        "    y_true = K.reshape(y_true, (-1, K.shape(y_true)[-1]))\n",
        "    y_pred = K.reshape(y_pred, (-1, K.shape(y_pred)[-1]))\n",
        "    top_k = K.in_top_k(y_pred, K.cast(K.max(y_true, axis=-1), 'int32'), k)\n",
        "    return K.reshape(top_k, original_shape[:-1])\n",
        "\n",
        "def sparse_temporal_top_k_categorical_accuracy_per_sequence(y_true, y_pred, k=5):\n",
        "    original_shape = K.shape(y_true)\n",
        "    y_true = K.reshape(y_true, (-1, K.shape(y_true)[-1]))\n",
        "    y_pred = K.reshape(y_pred, (-1, K.shape(y_pred)[-1]))\n",
        "    top_k = K.in_top_k(y_pred, K.cast(K.max(y_true, axis=-1), 'int32'), k)\n",
        "    perfect = K.min(K.cast(top_k, 'int32'), axis=-1)\n",
        "    return perfect #K.expand_dims(perfect, axis=-1)\n",
        "\n",
        "def sparse(y_true, y_pred):\n",
        "    return sparse_categorical_accuracy(y_true, y_pred)\n",
        "def sparse1(y_true, y_pred):\n",
        "    return sparse_temporal_top_k_categorical_accuracy(y_true, y_pred, k=1)\n",
        "def perfect(y_true, y_pred):\n",
        "    return sparse_categorical_accuracy_per_sequence(y_true, y_pred)\n",
        "def perfect1(y_true, y_pred):\n",
        "    return sparse_temporal_top_k_categorical_accuracy_per_sequence(y_true, y_pred, k=1)\n",
        "def sparse5(y_true, y_pred):\n",
        "    return sparse_temporal_top_k_categorical_accuracy(y_true, y_pred, k=5)\n",
        "def perfect5(y_true, y_pred):\n",
        "    return sparse_temporal_top_k_categorical_accuracy_per_sequence(y_true, y_pred, k=5)\n",
        "def fscore(y_true, y_pred):\n",
        "    recall = K.mean(sparse_categorical_accuracy(y_true, y_pred))\n",
        "    precision = K.mean(sparse_categorical_accuracy_per_sequence(y_true, y_pred))\n",
        "    return 2 * ((recall * precision)/(recall + precision))\n",
        "\n",
        "\n",
        "units_k=embed_size\n",
        "units_v=embed_size//3\n",
        "units=512\n",
        "\n",
        "metric_list = [sparse, sparse1, perfect, perfect1, sparse5, perfect5]\n",
        "metric_names = ['sparse', 'sparse1', 'perfect', 'perfect1', 'sparse5', 'perfect5']\n",
        "\n",
        "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = layers.Lambda(UniversalEmbedding, output_shape=(embed_size,), name='TF-Hub')(input_text)\n",
        "x = layers.RepeatVector(maxlen)(x)\n",
        "if False:\n",
        "    #x = layers.Dropout(0.1)(x)\n",
        "    x = AttentionBlock(embed_size, k_size=units_k, v_size=units_v)(x)\n",
        "x = get_lstm(units, return_sequences=True)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "# with 0.1, perfect peaked at 40 epochs\n",
        "x = layers.Dense(max_features, activation='softmax')(x)\n",
        "#x = layers.Reshape((-1, max_features * maxlen))(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=[input_text], outputs=x)\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=metric_list)\n",
        "model.summary()\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "\n",
        "print('Train...')\n",
        "history = None\n",
        "use_saved_model=False\n",
        "if not use_saved_model or not os.path.exists('./model.h5'):\n",
        "  with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    session.run(tf.tables_initializer())\n",
        "\n",
        "    history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=50,\n",
        "          verbose=2,\n",
        "          validation_data=[x_test, y_test])\n",
        "    model.save_weights('./model.h5')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0627 21:56:42.921517 140591835309952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0627 21:56:42.922987 140591835309952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0627 21:56:44.332704 140591835309952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0627 21:56:44.945052 140591835309952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0627 21:56:44.955622 140591835309952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0627 21:56:44.996932 140591835309952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0627 21:56:45.019266 140591835309952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "TF-Hub (Lambda)              (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 5, 512)            0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 5, 512)            2101248   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 512)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5, 16000)          8208000   \n",
            "=================================================================\n",
            "Total params: 10,309,248\n",
            "Trainable params: 10,309,248\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0627 21:56:48.094377 140591835309952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 71716 samples, validate on 23906 samples\n",
            "Epoch 1/50\n",
            " - 91s - loss: 4.6094 - sparse: 0.2368 - sparse1: 0.2368 - perfect: 0.0035 - perfect1: 0.0000e+00 - sparse5: 0.4214 - perfect5: 0.0000e+00 - val_loss: 3.2398 - val_sparse: 0.3952 - val_sparse1: 0.3952 - val_perfect: 0.0220 - val_perfect1: 0.0000e+00 - val_sparse5: 0.6248 - val_perfect5: 0.0000e+00\n",
            "Epoch 2/50\n",
            " - 87s - loss: 2.9758 - sparse: 0.4260 - sparse1: 0.4260 - perfect: 0.0349 - perfect1: 0.0000e+00 - sparse5: 0.6580 - perfect5: 0.0000e+00 - val_loss: 2.5235 - val_sparse: 0.5026 - val_sparse1: 0.5026 - val_perfect: 0.0737 - val_perfect1: 0.0000e+00 - val_sparse5: 0.7261 - val_perfect5: 0.0000e+00\n",
            "Epoch 3/50\n",
            " - 86s - loss: 2.4466 - sparse: 0.5008 - sparse1: 0.5008 - perfect: 0.0741 - perfect1: 0.0000e+00 - sparse5: 0.7314 - perfect5: 0.0000e+00 - val_loss: 2.1979 - val_sparse: 0.5556 - val_sparse1: 0.5556 - val_perfect: 0.1190 - val_perfect1: 0.0000e+00 - val_sparse5: 0.7725 - val_perfect5: 0.0000e+00\n",
            "Epoch 4/50\n",
            " - 85s - loss: 2.1434 - sparse: 0.5469 - sparse1: 0.5469 - perfect: 0.1058 - perfect1: 0.0000e+00 - sparse5: 0.7732 - perfect5: 0.0000e+00 - val_loss: 2.0044 - val_sparse: 0.5882 - val_sparse1: 0.5882 - val_perfect: 0.1560 - val_perfect1: 0.0000e+00 - val_sparse5: 0.7974 - val_perfect5: 0.0000e+00\n",
            "Epoch 5/50\n",
            " - 86s - loss: 1.9322 - sparse: 0.5814 - sparse1: 0.5814 - perfect: 0.1339 - perfect1: 0.0000e+00 - sparse5: 0.8013 - perfect5: 0.0000e+00 - val_loss: 1.8886 - val_sparse: 0.6083 - val_sparse1: 0.6083 - val_perfect: 0.1825 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8120 - val_perfect5: 0.0000e+00\n",
            "Epoch 6/50\n",
            " - 85s - loss: 1.7756 - sparse: 0.6063 - sparse1: 0.6063 - perfect: 0.1553 - perfect1: 0.0000e+00 - sparse5: 0.8221 - perfect5: 5.5776e-05 - val_loss: 1.7892 - val_sparse: 0.6256 - val_sparse1: 0.6256 - val_perfect: 0.2027 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8255 - val_perfect5: 0.0000e+00\n",
            "Epoch 7/50\n",
            " - 85s - loss: 1.6486 - sparse: 0.6287 - sparse1: 0.6287 - perfect: 0.1772 - perfect1: 0.0000e+00 - sparse5: 0.8389 - perfect5: 0.0000e+00 - val_loss: 1.7350 - val_sparse: 0.6379 - val_sparse1: 0.6379 - val_perfect: 0.2204 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8307 - val_perfect5: 0.0000e+00\n",
            "Epoch 8/50\n",
            " - 85s - loss: 1.5428 - sparse: 0.6461 - sparse1: 0.6461 - perfect: 0.1967 - perfect1: 0.0000e+00 - sparse5: 0.8524 - perfect5: 0.0000e+00 - val_loss: 1.6810 - val_sparse: 0.6462 - val_sparse1: 0.6462 - val_perfect: 0.2306 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8373 - val_perfect5: 0.0000e+00\n",
            "Epoch 9/50\n",
            " - 85s - loss: 1.4544 - sparse: 0.6635 - sparse1: 0.6635 - perfect: 0.2155 - perfect1: 0.0000e+00 - sparse5: 0.8632 - perfect5: 0.0000e+00 - val_loss: 1.6483 - val_sparse: 0.6537 - val_sparse1: 0.6537 - val_perfect: 0.2423 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8428 - val_perfect5: 0.0000e+00\n",
            "Epoch 10/50\n",
            " - 85s - loss: 1.3742 - sparse: 0.6784 - sparse1: 0.6784 - perfect: 0.2313 - perfect1: 0.0000e+00 - sparse5: 0.8740 - perfect5: 5.5776e-05 - val_loss: 1.6153 - val_sparse: 0.6608 - val_sparse1: 0.6608 - val_perfect: 0.2538 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8475 - val_perfect5: 0.0000e+00\n",
            "Epoch 11/50\n",
            " - 85s - loss: 1.3065 - sparse: 0.6914 - sparse1: 0.6914 - perfect: 0.2458 - perfect1: 0.0000e+00 - sparse5: 0.8820 - perfect5: 0.0000e+00 - val_loss: 1.6001 - val_sparse: 0.6648 - val_sparse1: 0.6648 - val_perfect: 0.2593 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8495 - val_perfect5: 0.0000e+00\n",
            "Epoch 12/50\n",
            " - 85s - loss: 1.2451 - sparse: 0.7031 - sparse1: 0.7031 - perfect: 0.2582 - perfect1: 0.0000e+00 - sparse5: 0.8901 - perfect5: 0.0000e+00 - val_loss: 1.5774 - val_sparse: 0.6691 - val_sparse1: 0.6691 - val_perfect: 0.2664 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8522 - val_perfect5: 0.0000e+00\n",
            "Epoch 13/50\n",
            " - 85s - loss: 1.1947 - sparse: 0.7129 - sparse1: 0.7129 - perfect: 0.2702 - perfect1: 0.0000e+00 - sparse5: 0.8962 - perfect5: 0.0000e+00 - val_loss: 1.5623 - val_sparse: 0.6738 - val_sparse1: 0.6738 - val_perfect: 0.2741 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8537 - val_perfect5: 0.0000e+00\n",
            "Epoch 14/50\n",
            " - 85s - loss: 1.1456 - sparse: 0.7219 - sparse1: 0.7219 - perfect: 0.2805 - perfect1: 0.0000e+00 - sparse5: 0.9026 - perfect5: 0.0000e+00 - val_loss: 1.5612 - val_sparse: 0.6755 - val_sparse1: 0.6755 - val_perfect: 0.2798 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8550 - val_perfect5: 0.0000e+00\n",
            "Epoch 15/50\n",
            " - 85s - loss: 1.1002 - sparse: 0.7309 - sparse1: 0.7309 - perfect: 0.2919 - perfect1: 0.0000e+00 - sparse5: 0.9080 - perfect5: 0.0000e+00 - val_loss: 1.5475 - val_sparse: 0.6789 - val_sparse1: 0.6789 - val_perfect: 0.2844 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8573 - val_perfect5: 0.0000e+00\n",
            "Epoch 16/50\n",
            " - 85s - loss: 1.0638 - sparse: 0.7383 - sparse1: 0.7383 - perfect: 0.3025 - perfect1: 0.0000e+00 - sparse5: 0.9124 - perfect5: 0.0000e+00 - val_loss: 1.5490 - val_sparse: 0.6796 - val_sparse1: 0.6796 - val_perfect: 0.2841 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8580 - val_perfect5: 0.0000e+00\n",
            "Epoch 17/50\n",
            " - 85s - loss: 1.0296 - sparse: 0.7453 - sparse1: 0.7453 - perfect: 0.3115 - perfect1: 0.0000e+00 - sparse5: 0.9166 - perfect5: 5.5776e-05 - val_loss: 1.5397 - val_sparse: 0.6842 - val_sparse1: 0.6842 - val_perfect: 0.2929 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8590 - val_perfect5: 0.0000e+00\n",
            "Epoch 18/50\n",
            " - 85s - loss: 0.9984 - sparse: 0.7519 - sparse1: 0.7519 - perfect: 0.3207 - perfect1: 0.0000e+00 - sparse5: 0.9201 - perfect5: 5.5776e-05 - val_loss: 1.5363 - val_sparse: 0.6863 - val_sparse1: 0.6863 - val_perfect: 0.2974 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8597 - val_perfect5: 0.0000e+00\n",
            "Epoch 19/50\n",
            " - 85s - loss: 0.9674 - sparse: 0.7582 - sparse1: 0.7582 - perfect: 0.3290 - perfect1: 0.0000e+00 - sparse5: 0.9243 - perfect5: 5.5776e-05 - val_loss: 1.5577 - val_sparse: 0.6840 - val_sparse1: 0.6840 - val_perfect: 0.2952 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8595 - val_perfect5: 0.0000e+00\n",
            "Epoch 20/50\n",
            " - 85s - loss: 0.9376 - sparse: 0.7645 - sparse1: 0.7645 - perfect: 0.3382 - perfect1: 0.0000e+00 - sparse5: 0.9268 - perfect5: 5.5776e-05 - val_loss: 1.5370 - val_sparse: 0.6879 - val_sparse1: 0.6879 - val_perfect: 0.3013 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8614 - val_perfect5: 0.0000e+00\n",
            "Epoch 21/50\n",
            " - 84s - loss: 0.9123 - sparse: 0.7691 - sparse1: 0.7691 - perfect: 0.3445 - perfect1: 0.0000e+00 - sparse5: 0.9302 - perfect5: 5.5776e-05 - val_loss: 1.5353 - val_sparse: 0.6889 - val_sparse1: 0.6889 - val_perfect: 0.3028 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8609 - val_perfect5: 0.0000e+00\n",
            "Epoch 22/50\n",
            " - 85s - loss: 0.8892 - sparse: 0.7740 - sparse1: 0.7740 - perfect: 0.3515 - perfect1: 0.0000e+00 - sparse5: 0.9327 - perfect5: 0.0000e+00 - val_loss: 1.5567 - val_sparse: 0.6886 - val_sparse1: 0.6886 - val_perfect: 0.3036 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8611 - val_perfect5: 0.0000e+00\n",
            "Epoch 23/50\n",
            " - 85s - loss: 0.8663 - sparse: 0.7786 - sparse1: 0.7786 - perfect: 0.3577 - perfect1: 0.0000e+00 - sparse5: 0.9355 - perfect5: 5.5776e-05 - val_loss: 1.5523 - val_sparse: 0.6896 - val_sparse1: 0.6896 - val_perfect: 0.3051 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8615 - val_perfect5: 0.0000e+00\n",
            "Epoch 24/50\n",
            " - 85s - loss: 0.8489 - sparse: 0.7825 - sparse1: 0.7825 - perfect: 0.3639 - perfect1: 0.0000e+00 - sparse5: 0.9374 - perfect5: 0.0000e+00 - val_loss: 1.5491 - val_sparse: 0.6924 - val_sparse1: 0.6924 - val_perfect: 0.3102 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8619 - val_perfect5: 0.0000e+00\n",
            "Epoch 25/50\n",
            " - 85s - loss: 0.8278 - sparse: 0.7869 - sparse1: 0.7869 - perfect: 0.3706 - perfect1: 0.0000e+00 - sparse5: 0.9398 - perfect5: 4.4620e-04 - val_loss: 1.5551 - val_sparse: 0.6922 - val_sparse1: 0.6922 - val_perfect: 0.3067 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8620 - val_perfect5: 0.0000e+00\n",
            "Epoch 26/50\n",
            " - 85s - loss: 0.8115 - sparse: 0.7915 - sparse1: 0.7915 - perfect: 0.3798 - perfect1: 0.0000e+00 - sparse5: 0.9413 - perfect5: 0.0000e+00 - val_loss: 1.5450 - val_sparse: 0.6942 - val_sparse1: 0.6942 - val_perfect: 0.3138 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8624 - val_perfect5: 0.0000e+00\n",
            "Epoch 27/50\n",
            " - 85s - loss: 0.7931 - sparse: 0.7951 - sparse1: 0.7951 - perfect: 0.3827 - perfect1: 0.0000e+00 - sparse5: 0.9436 - perfect5: 5.5776e-05 - val_loss: 1.5566 - val_sparse: 0.6945 - val_sparse1: 0.6945 - val_perfect: 0.3128 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8634 - val_perfect5: 0.0000e+00\n",
            "Epoch 28/50\n",
            " - 85s - loss: 0.7810 - sparse: 0.7970 - sparse1: 0.7970 - perfect: 0.3859 - perfect1: 0.0000e+00 - sparse5: 0.9450 - perfect5: 5.0198e-04 - val_loss: 1.5626 - val_sparse: 0.6945 - val_sparse1: 0.6945 - val_perfect: 0.3131 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8622 - val_perfect5: 0.0000e+00\n",
            "Epoch 29/50\n",
            " - 85s - loss: 0.7621 - sparse: 0.8013 - sparse1: 0.8013 - perfect: 0.3939 - perfect1: 0.0000e+00 - sparse5: 0.9469 - perfect5: 0.0018 - val_loss: 1.5627 - val_sparse: 0.6955 - val_sparse1: 0.6955 - val_perfect: 0.3158 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8632 - val_perfect5: 0.0000e+00\n",
            "Epoch 30/50\n",
            " - 86s - loss: 0.7492 - sparse: 0.8041 - sparse1: 0.8041 - perfect: 0.3977 - perfect1: 0.0000e+00 - sparse5: 0.9482 - perfect5: 0.0018 - val_loss: 1.5682 - val_sparse: 0.6961 - val_sparse1: 0.6961 - val_perfect: 0.3173 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8627 - val_perfect5: 0.0000e+00\n",
            "Epoch 31/50\n",
            " - 85s - loss: 0.7379 - sparse: 0.8067 - sparse1: 0.8067 - perfect: 0.4033 - perfect1: 0.0000e+00 - sparse5: 0.9493 - perfect5: 9.4818e-04 - val_loss: 1.5744 - val_sparse: 0.6961 - val_sparse1: 0.6961 - val_perfect: 0.3210 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8618 - val_perfect5: 0.0000e+00\n",
            "Epoch 32/50\n",
            " - 85s - loss: 0.7254 - sparse: 0.8100 - sparse1: 0.8100 - perfect: 0.4101 - perfect1: 0.0000e+00 - sparse5: 0.9506 - perfect5: 8.9241e-04 - val_loss: 1.5752 - val_sparse: 0.6986 - val_sparse1: 0.6986 - val_perfect: 0.3229 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8632 - val_perfect5: 0.0000e+00\n",
            "Epoch 33/50\n",
            " - 85s - loss: 0.7132 - sparse: 0.8117 - sparse1: 0.8117 - perfect: 0.4116 - perfect1: 0.0000e+00 - sparse5: 0.9519 - perfect5: 9.4818e-04 - val_loss: 1.5779 - val_sparse: 0.6971 - val_sparse1: 0.6971 - val_perfect: 0.3219 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8632 - val_perfect5: 0.0000e+00\n",
            "Epoch 34/50\n",
            " - 85s - loss: 0.7031 - sparse: 0.8142 - sparse1: 0.8142 - perfect: 0.4154 - perfect1: 0.0000e+00 - sparse5: 0.9531 - perfect5: 0.0014 - val_loss: 1.5845 - val_sparse: 0.6978 - val_sparse1: 0.6978 - val_perfect: 0.3216 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8628 - val_perfect5: 0.0000e+00\n",
            "Epoch 35/50\n",
            " - 84s - loss: 0.6918 - sparse: 0.8167 - sparse1: 0.8167 - perfect: 0.4216 - perfect1: 0.0000e+00 - sparse5: 0.9547 - perfect5: 0.0014 - val_loss: 1.5904 - val_sparse: 0.6975 - val_sparse1: 0.6975 - val_perfect: 0.3212 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8629 - val_perfect5: 0.0000e+00\n",
            "Epoch 36/50\n",
            " - 84s - loss: 0.6812 - sparse: 0.8187 - sparse1: 0.8187 - perfect: 0.4246 - perfect1: 0.0000e+00 - sparse5: 0.9555 - perfect5: 8.9241e-04 - val_loss: 1.5936 - val_sparse: 0.6968 - val_sparse1: 0.6968 - val_perfect: 0.3210 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8630 - val_perfect5: 0.0000e+00\n",
            "Epoch 37/50\n",
            " - 84s - loss: 0.6712 - sparse: 0.8217 - sparse1: 0.8217 - perfect: 0.4305 - perfect1: 0.0000e+00 - sparse5: 0.9562 - perfect5: 0.0014 - val_loss: 1.5878 - val_sparse: 0.6990 - val_sparse1: 0.6990 - val_perfect: 0.3254 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8631 - val_perfect5: 0.0000e+00\n",
            "Epoch 38/50\n",
            " - 85s - loss: 0.6633 - sparse: 0.8228 - sparse1: 0.8228 - perfect: 0.4321 - perfect1: 0.0000e+00 - sparse5: 0.9571 - perfect5: 0.0040 - val_loss: 1.5958 - val_sparse: 0.6977 - val_sparse1: 0.6977 - val_perfect: 0.3236 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8629 - val_perfect5: 0.0000e+00\n",
            "Epoch 39/50\n",
            " - 85s - loss: 0.6558 - sparse: 0.8246 - sparse1: 0.8246 - perfect: 0.4364 - perfect1: 0.0000e+00 - sparse5: 0.9584 - perfect5: 0.0022 - val_loss: 1.6106 - val_sparse: 0.6980 - val_sparse1: 0.6980 - val_perfect: 0.3215 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8639 - val_perfect5: 0.0000e+00\n",
            "Epoch 40/50\n",
            " - 85s - loss: 0.6438 - sparse: 0.8276 - sparse1: 0.8276 - perfect: 0.4416 - perfect1: 0.0000e+00 - sparse5: 0.9595 - perfect5: 0.0040 - val_loss: 1.6153 - val_sparse: 0.6983 - val_sparse1: 0.6983 - val_perfect: 0.3232 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8630 - val_perfect5: 0.0000e+00\n",
            "Epoch 41/50\n",
            " - 85s - loss: 0.6376 - sparse: 0.8287 - sparse1: 0.8287 - perfect: 0.4434 - perfect1: 0.0000e+00 - sparse5: 0.9601 - perfect5: 0.0036 - val_loss: 1.6086 - val_sparse: 0.7008 - val_sparse1: 0.7008 - val_perfect: 0.3274 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8625 - val_perfect5: 0.0000e+00\n",
            "Epoch 42/50\n",
            " - 85s - loss: 0.6299 - sparse: 0.8305 - sparse1: 0.8305 - perfect: 0.4472 - perfect1: 0.0000e+00 - sparse5: 0.9605 - perfect5: 0.0036 - val_loss: 1.6164 - val_sparse: 0.6981 - val_sparse1: 0.6981 - val_perfect: 0.3221 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8617 - val_perfect5: 0.0000e+00\n",
            "Epoch 43/50\n",
            " - 85s - loss: 0.6250 - sparse: 0.8322 - sparse1: 0.8322 - perfect: 0.4503 - perfect1: 0.0000e+00 - sparse5: 0.9612 - perfect5: 0.0062 - val_loss: 1.6180 - val_sparse: 0.7004 - val_sparse1: 0.7004 - val_perfect: 0.3293 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8616 - val_perfect5: 0.0000e+00\n",
            "Epoch 44/50\n",
            " - 85s - loss: 0.6165 - sparse: 0.8336 - sparse1: 0.8336 - perfect: 0.4523 - perfect1: 0.0000e+00 - sparse5: 0.9623 - perfect5: 0.0059 - val_loss: 1.6150 - val_sparse: 0.7005 - val_sparse1: 0.7005 - val_perfect: 0.3293 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8622 - val_perfect5: 0.0000e+00\n",
            "Epoch 45/50\n",
            " - 85s - loss: 0.6121 - sparse: 0.8347 - sparse1: 0.8347 - perfect: 0.4565 - perfect1: 0.0000e+00 - sparse5: 0.9623 - perfect5: 0.0059 - val_loss: 1.6169 - val_sparse: 0.6993 - val_sparse1: 0.6993 - val_perfect: 0.3283 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8625 - val_perfect5: 0.0000e+00\n",
            "Epoch 46/50\n",
            " - 84s - loss: 0.6026 - sparse: 0.8369 - sparse1: 0.8369 - perfect: 0.4605 - perfect1: 0.0000e+00 - sparse5: 0.9633 - perfect5: 0.0049 - val_loss: 1.6207 - val_sparse: 0.7004 - val_sparse1: 0.7004 - val_perfect: 0.3320 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8635 - val_perfect5: 0.0000e+00\n",
            "Epoch 47/50\n",
            " - 84s - loss: 0.5975 - sparse: 0.8381 - sparse1: 0.8381 - perfect: 0.4611 - perfect1: 0.0000e+00 - sparse5: 0.9639 - perfect5: 0.0059 - val_loss: 1.6360 - val_sparse: 0.6994 - val_sparse1: 0.6994 - val_perfect: 0.3269 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8628 - val_perfect5: 0.0000e+00\n",
            "Epoch 48/50\n",
            " - 84s - loss: 0.5924 - sparse: 0.8383 - sparse1: 0.8383 - perfect: 0.4626 - perfect1: 0.0000e+00 - sparse5: 0.9647 - perfect5: 0.0040 - val_loss: 1.6375 - val_sparse: 0.7008 - val_sparse1: 0.7008 - val_perfect: 0.3311 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8615 - val_perfect5: 0.0000e+00\n",
            "Epoch 49/50\n",
            " - 85s - loss: 0.5883 - sparse: 0.8396 - sparse1: 0.8396 - perfect: 0.4655 - perfect1: 0.0000e+00 - sparse5: 0.9651 - perfect5: 0.0054 - val_loss: 1.6543 - val_sparse: 0.7006 - val_sparse1: 0.7006 - val_perfect: 0.3316 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8615 - val_perfect5: 0.0000e+00\n",
            "Epoch 50/50\n",
            " - 84s - loss: 0.5809 - sparse: 0.8417 - sparse1: 0.8417 - perfect: 0.4696 - perfect1: 0.0000e+00 - sparse5: 0.9655 - perfect5: 0.0063 - val_loss: 1.6466 - val_sparse: 0.7012 - val_sparse1: 0.7012 - val_perfect: 0.3303 - val_perfect1: 0.0000e+00 - val_sparse5: 0.8616 - val_perfect5: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHy1cTDVP_XZ",
        "colab_type": "code",
        "outputId": "de135465-5e74-46c2-961b-80a271af360c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "\n",
        "if history != None:\n",
        "  # summarize history for accuracy\n",
        "  for m in metric_names:\n",
        "      plt.plot(history.history['val_' + m])\n",
        "  plt.title('model accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(metric_names, loc='upper right')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEWCAYAAACdaNcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6ZR0kc7X-tm",
        "colab_type": "code",
        "outputId": "fbf9a2f1-9eca-4d36-955c-9b700d6923eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "x_short = x_test[0:1000]\n",
        "y_short = y_test[0:1000]\n",
        "predicts = None\n",
        "\n",
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  model.load_weights('./model.h5')  \n",
        "  #eval = model.evaluate(x_test, y_test)\n",
        "  #print('model.evaluate on val holdout: ' ,model.metrics_names, eval)\n",
        "  print('history: ', history)\n",
        "  predicts = model.predict(x_short, batch_size=32)\n",
        "  print('shape: {}'.format(predicts.shape))\n",
        "\n",
        "print(len(predicts[0]))\n",
        "print(len(predicts[0][0]))\n",
        "print(predicts[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "history:  <keras.callbacks.History object at 0x7fddb1236dd8>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fddbb138e10>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
            "    self._session._session, self._handle)\n",
            "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "shape: (1000, 5, 16000)\n",
            "5\n",
            "16000\n",
            "[[7.3998235e-05 3.1968710e-08 7.8295907e-06 ... 3.1912968e-08\n",
            "  3.1109796e-08 3.1769822e-08]\n",
            " [1.9782770e-04 3.4644457e-10 2.2502853e-08 ... 3.2651468e-10\n",
            "  3.3602326e-10 3.3877956e-10]\n",
            " [8.7786204e-04 8.1113383e-09 7.1187264e-05 ... 7.9476870e-09\n",
            "  8.1808516e-09 8.2170706e-09]\n",
            " [4.2917053e-03 6.4278849e-10 8.9306632e-06 ... 6.0054517e-10\n",
            "  6.1138261e-10 6.2123207e-10]\n",
            " [6.7159700e-01 1.6881557e-12 1.4885356e-06 ... 1.7063552e-12\n",
            "  1.7310891e-12 1.6589588e-12]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFy2tfyIYOtY",
        "colab_type": "code",
        "outputId": "c76198c7-7b4b-4880-8d2c-e59ce89b26b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def maxindx(pred):\n",
        "    maxi=-1\n",
        "    maxv=-1.0\n",
        "    for x in range(len(pred)):\n",
        "        if pred[x] > maxv:\n",
        "            maxv = pred[x]\n",
        "            maxi = x\n",
        "    return (maxi, maxv)\n",
        "\n",
        "def match(data, prediction):\n",
        "    good = 0\n",
        "    total = 0\n",
        "    for i in range(len(data)):\n",
        "        #print(data[i], np.argmax(prediction[i]))\n",
        "        if data[i] == np.argmax(prediction[i]):\n",
        "            good += 1\n",
        "        total += 1\n",
        "    #print('{}, {}'.format(good, total))\n",
        "    if (total == 0):\n",
        "        return 0\n",
        "    return good / total\n",
        "\n",
        "parallel = 0.0\n",
        "serial = 0.0\n",
        "total = 0\n",
        "for n in range(len(y_short)):\n",
        "    #print(len(short[n]))\n",
        "    check = match(y_short[n], predicts[n])\n",
        "    parallel += check\n",
        "    if check > 0.9999:\n",
        "        serial += 1\n",
        "    total += 1\n",
        "\n",
        "print('Parallel, serial: ', parallel / total, serial / total)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parallel, serial:  0.710599999999998 0.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNWVxMyKd3P8",
        "colab_type": "code",
        "outputId": "dbd08274-be93-4eee-f4b8-c1859dc85caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/LanceNorskog/test_data/master/haiku_5.txt\n",
        "!rm -f toki_cmu.json\n",
        "!wget -nc https://raw.githubusercontent.com/LanceNorskog/deep_meter_2/master/toki_cmu.json\n",
        "import collections \n",
        "\n",
        "big_data_file = 'haiku_5.txt'\n",
        "big_text = []\n",
        "big_haiku = []\n",
        "big_sylls = set()\n",
        "for index, word in enumerate(word2sylls):\n",
        "    sylls = word2sylls[word]\n",
        "    for syll in sylls:\n",
        "        syll = syll.replace(' ', '').lower()\n",
        "        big_sylls.add(syll)\n",
        "\n",
        "    \n",
        "with open(big_data_file) as f:\n",
        "    for line in f.readlines():\n",
        "        big_text.append(line.strip().split('\\t')[0])\n",
        "        big_haiku.append(line.strip().split('\\t')[1])\n",
        "        \n",
        "big_data = np.zeros((len(big_text), maxlen, 1), dtype='int32')\n",
        "for i in range(len(big_text)):    \n",
        "    seq = text.text_to_word_sequence(big_haiku[i])\n",
        "    sylls = []\n",
        "    for word in seq:\n",
        "        if word in word2sylls:\n",
        "            for syll in word2sylls[word]:\n",
        "                sylls.append(syll.replace(' ', '').lower())\n",
        "    for j in range(5):\n",
        "        if len(sylls) > j:\n",
        "            big_data[i][j][0] = syll2idx[sylls[j]]\n",
        "    if i == 0:\n",
        "        print(big_haiku[i])\n",
        "        print(sylls)\n",
        "        print(big_data[i])\n",
        "   \n",
        "print('Full length clauses: ', len(big_text))\n",
        "big_text = np.array(big_text)\n",
        "\n",
        "def printhistory(history):\n",
        "    print(metrics_names.join(','))\n",
        "    out = ''\n",
        "    for m in metrics_names:\n",
        "        out += history[m][0] + ','\n",
        "    print(out[0:-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘haiku_5.txt’ already there; not retrieving.\n",
            "\n",
            "--2019-06-28 01:51:33--  https://raw.githubusercontent.com/LanceNorskog/deep_meter_2/master/toki_cmu.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 357359 (349K) [text/plain]\n",
            "Saving to: ‘toki_cmu.json’\n",
            "\n",
            "toki_cmu.json       100%[===================>] 348.98K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-06-28 01:51:33 (6.83 MB/s) - ‘toki_cmu.json’ saved [357359/357359]\n",
            "\n",
            "backyards to stockyards\n",
            "['baek', 'yaardz', 'tuw', 'staak', 'yaardz']\n",
            "[[ 6862]\n",
            " [14341]\n",
            " [ 4364]\n",
            " [ 7884]\n",
            " [14341]]\n",
            "Full length clauses:  77203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unppo_tZk4fC",
        "colab_type": "code",
        "outputId": "06ff170b-f846-4f41-81d2-f6e44678fc98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  model.load_weights('./model.h5')  \n",
        "  eval_small = model.evaluate(np.array(big_haiku), big_data)\n",
        "  print('model.evaluate on haiku clauses: ' ,model.metrics_names, eval_small)\n",
        "  print('history: ', history)\n",
        "  eval_big = model.evaluate(np.array(big_text), big_data)\n",
        "  print('model.evaluate on long clauses: ' ,model.metrics_names, eval_big)\n",
        "  print('history: ', history)\n",
        "  biglen = len(big_text)\n",
        "  #for i in range(0, len(big_text), batch_size):\n",
        "  #  predicts = model.predict(big_text[i:i + batch_size], batch_size=batch_size)\n",
        "  #  print('shape: {}'.format(predicts.shape))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  160/77203 [..............................] - ETA: 7:17 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fdd4fad9ef0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
            "    self._session._session, self._handle)\n",
            "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "77203/77203 [==============================] - 52s 678us/step\n",
            "model.evaluate on haiku clauses:  ['loss', 'sparse', 'sparse1', 'perfect', 'perfect1', 'sparse5', 'perfect5'] [0.39229551194467754, 0.9185964275849859, 0.9185964275849859, 0.7514992940627069, 0.02984339986788078, 0.9731875691959194, 0.19381371190238722]\n",
            "history:  <keras.callbacks.History object at 0x7fddb1236dd8>\n",
            "77203/77203 [==============================] - 54s 706us/step\n",
            "model.evaluate on long clauses:  ['loss', 'sparse', 'sparse1', 'perfect', 'perfect1', 'sparse5', 'perfect5'] [4.826785261340134, 0.45996917251441005, 0.45996917251441005, 0.27071486859550553, 0.0, 0.6165641231129099, 0.0]\n",
            "history:  <keras.callbacks.History object at 0x7fddb1236dd8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c30OLFH9kvtE",
        "colab_type": "code",
        "outputId": "d7b958e2-ebb6-4206-a85a-854c84dbfaa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "def printhistory(history):\n",
        "    print(','.join(model.metrics_names))\n",
        "    out = ''\n",
        "    for i in range(len(model.metrics_names)):\n",
        "        out += str(history[i]) + ','\n",
        "    print(out[0:-1])\n",
        "    \n",
        "printhistory(eval_small)\n",
        "printhistory(eval_big)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss,sparse,sparse1,perfect,perfect1,sparse5,perfect5\n",
            "0.39229551194467754,0.9185964275849859,0.9185964275849859,0.7514992940627069,0.02984339986788078,0.9731875691959194,0.19381371190238722\n",
            "loss,sparse,sparse1,perfect,perfect1,sparse5,perfect5\n",
            "4.826785261340134,0.45996917251441005,0.45996917251441005,0.27071486859550553,0.0,0.6165641231129099,0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogOac-7KoPYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report(data, prediction):\n",
        "    def match(data, prediction):\n",
        "        good = 0\n",
        "        top5 = 0\n",
        "        count = 0\n",
        "        for i in range(len(data)):\n",
        "            topind = np.argsort(prediction[i])\n",
        "            if data[i][0] == topind[-1]:\n",
        "                good += 1\n",
        "            topind = topind[-5:len(topind)]\n",
        "            for j in range(5):\n",
        "                if data[i][0] == topind[j]:\n",
        "                    top5 += 1\n",
        "                    break\n",
        "            count += 1\n",
        "        return (good, top5, count)\n",
        "\n",
        "    _sparse = 0.0\n",
        "    _perfect = 0.0\n",
        "    _sparse5 = 0.0\n",
        "    _perfect5 = 0.0\n",
        "    _total = 0\n",
        "    for n in range(len(data)):\n",
        "        #print(len(short[n]))\n",
        "        (good, top5, count) = match(data[n], predicts[n])\n",
        "        if count == 0:\n",
        "            continue\n",
        "        _sparse += good/count\n",
        "        _sparse5 += top5/count\n",
        "        if good == count:\n",
        "            _perfect += 1  \n",
        "        if top5 == count:\n",
        "            _perfect5 += 1\n",
        "        _total += 1\n",
        "    return {'sparse':_sparse/_total, 'perfect': _perfect/_total, 'sparse5': _sparse5/_total, 'perfect5': _perfect5/_total}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYiGf2LOtTbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigbatch = batch_size * 32\n",
        "big_text = np.array(big_text)\n",
        "big_haiku = np.array(big_haiku)\n",
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  model.load_weights('./model.h5')  \n",
        "  predicts = model.predict(big_haiku[0: bigbatch], batch_size=bigbatch)\n",
        "  rep = report(big_data[0: bigbatch], predicts)\n",
        "  print(\"short {}\".format(rep))\n",
        "  biglen = len(big_text)\n",
        "  for i in range(0, biglen, bigbatch):\n",
        "    predicts = model.predict(big_haiku[i:i + bigbatch], batch_size=bigbatch)\n",
        "    rep = report(big_data[i:i + bigbatch], predicts)\n",
        "    print(\"[{}] {}\".format(i, rep))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BftiQv1HsRrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}