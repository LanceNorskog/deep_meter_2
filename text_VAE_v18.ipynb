{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_VAE_v18.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Gk6tMFqf3TDw",
        "colab_type": "code",
        "outputId": "3074bf61-d958-475a-fe8d-4adffad68d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "BASE_DIR = '/content/vae/'\n",
        "!mkdir -p $BASE_DIR\n",
        "%cd $BASE_DIR\n",
        "!wget -c -nc -q http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -n glove.6B.zip glove.6B.300d.txt \n",
        "!apt-get -yq install -q jq\n",
        "!wget -c -nc -q http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
        "!unzip -p annotations_trainval2014.zip annotations/captions_train2014.json > captions_train2014.json\n",
        "!jq -r '.annotations[]|.caption' < captions_train2014.json > sentences.txt\n",
        "!unzip -p annotations_trainval2014.zip annotations/captions_val2014.json > captions_val2014.json\n",
        "!jq -r '.annotations[]|.caption' < captions_val2014.json >> sentences.txt\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/vae\n",
            "Archive:  glove.6B.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fnTMkBByK6-Z",
        "colab_type": "code",
        "outputId": "86f093ac-e00e-410c-d40d-8f08466c69c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LKJCtg6J3aaE",
        "colab_type": "code",
        "outputId": "98984a1e-b1ef-4ad2-9c3a-25c0b88cda2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Bidirectional, Dense, Embedding, Input, Lambda, LSTM, RepeatVector, TimeDistributed, Layer, Activation, Dropout\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers.advanced_activations import ELU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam, Nadam\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from scipy import spatial\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import codecs\n",
        "import csv\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "hQkqX9ir3TD8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Directories and text loading\n",
        "Initially we will set the main directories and some variables regarding the characteristics of our texts.\n",
        "We set the maximum sequence length to 25, the maximun number of words in our vocabulary to 12000 and we will use 300-dimensional embeddings. Finally we load our texts from a csv. The text file is the train file of the Quora Kaggle challenge containing around 808000 sentences."
      ]
    },
    {
      "metadata": {
        "id": "OVOqQAqy3TED",
        "colab_type": "code",
        "outputId": "9b0c9578-851d-496a-a7df-467e08db074c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "EMBEDDING_DIM = 300\n",
        "TRAIN_DATA_FILE = BASE_DIR + 'sentences.txt'\n",
        "GLOVE_EMBEDDING = BASE_DIR + 'glove.6B.{0}d.txt'.format(EMBEDDING_DIM)\n",
        "MODEL_DIR='/content/gdrive/My Drive/Colab Notebooks'\n",
        "VALIDATION_SPLIT = 0.2\n",
        "MAX_SEQUENCE_LENGTH = 20\n",
        "MAX_NB_WORDS = 2000\n",
        "MAX_TRAIN=70000\n",
        "MAX_VALID=8000\n",
        "\n",
        "texts = [] \n",
        "with open(TRAIN_DATA_FILE) as f:\n",
        "    for line in f:\n",
        "        text = line[0:-1]\n",
        "        if len(text.split()) <= MAX_SEQUENCE_LENGTH:\n",
        "                texts.append(text)\n",
        "print('Found %s texts in train.csv' % len(texts))\n",
        "n_sents = len(texts)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 615599 texts in train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LF5u_CPW3TEO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Text Preprocessing\n",
        "To preprocess the text we will use the tokenizer and the text_to_sequences function from Keras\n"
      ]
    },
    {
      "metadata": {
        "id": "A4_IKGlx3TEW",
        "colab_type": "code",
        "outputId": "7330b25d-c7cc-437c-8820-df6b641527a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(MAX_NB_WORDS+1, oov_token='unk') #+1 for 'unk' token\n",
        "tokenizer.fit_on_texts(texts)\n",
        "print('Found %s unique tokens' % len(tokenizer.word_index))\n",
        "## **Key Step** to make it work correctly otherwise drops OOV tokens anyway!\n",
        "tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() if i <= MAX_NB_WORDS} # <= because tokenizer is 1 indexed\n",
        "tokenizer.word_index[tokenizer.oov_token] = MAX_NB_WORDS + 1\n",
        "word_index = tokenizer.word_index #the dict values start from 1 so this is fine with zeropadding\n",
        "index2word = {v: k for k, v in word_index.items()}\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "trimmed_texts = []\n",
        "trimmed_sequences = []\n",
        "for i in range(len(sequences)):\n",
        "    fail = False\n",
        "    for enc in sequences[i]:\n",
        "        if enc >= MAX_NB_WORDS:\n",
        "            fail = True\n",
        "    if not fail:\n",
        "        trimmed_texts.append(texts[i])\n",
        "        trimmed_sequences.append(sequences[i])\n",
        "texts = trimmed_texts\n",
        "sequences = trimmed_sequences\n",
        "print('Text sequences reduced to: {}'.format(len(sequences)))\n",
        "data_1 = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', data_1.shape)\n",
        "NB_WORDS = (min(tokenizer.num_words, len(word_index))+1) #+1 for zero padding \n",
        "\n",
        "data_val = data_1[MAX_TRAIN:MAX_TRAIN+MAX_VALID]\n",
        "data_train = data_1[:MAX_TRAIN]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 27756 unique tokens\n",
            "Text sequences reduced to: 424750\n",
            "Shape of data tensor: (424750, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9wVMQg4z3TEe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Word embeddings\n",
        "We will use pretrained Glove word embeddings as embeddings for our network. We create a matrix with one embedding for every word in our vocabulary and then we will pass this matrix as weights to the keras embedding layer of our model"
      ]
    },
    {
      "metadata": {
        "id": "HeNS36793TE0",
        "colab_type": "code",
        "outputId": "25254b3a-7aea-4495-e44b-34d876a236fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "f = open(GLOVE_EMBEDDING, encoding='utf8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "glove_embedding_matrix = np.zeros((NB_WORDS, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i < NB_WORDS: #+1 for 'unk' oov token\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            glove_embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            # words not found in embedding index will the word embedding of unk\n",
        "            glove_embedding_matrix[i] = embeddings_index.get('unk')\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(glove_embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n",
            "Null word embeddings: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RBm2TRRW3TFG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### VAE model\n",
        "Our model is based on a seq2seq architecture with a bidirectional LSTM encoder and an LSTM decoder and ELU activations.\n",
        "We feed the latent representation at every timestep as input to the decoder through \"RepeatVector(max_len)\".\n",
        "To avoid the one-hot representation of labels we use the \"tf.contrib.seq2seq.sequence_loss\" that requires as labels only the word indexes (the same that go in input to the embedding matrix) and calculates internally the final softmax (so the model ends with a dense layer with linear activation). Optionally the \"sequence_loss\" allows to use the sampled softmax which helps when dealing with large vocabularies (for example with a 50k words vocabulary) but in this I didn't use it. The decoder that we are using here is different from the one implemented in the paper; instead of feeding the context vector as initial state of the decoder and the predicted words as inputs, we are feeding the latent representation z as input at every timestep."
      ]
    },
    {
      "metadata": {
        "id": "Txwd9qFl3TFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "397d095b-3ab4-4718-e5b0-9eb8ff76c368"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "max_epochs = 100\n",
        "max_len = MAX_SEQUENCE_LENGTH\n",
        "emb_dim = EMBEDDING_DIM\n",
        "latent_dim = 128\n",
        "intermediate_dim = 512\n",
        "epsilon_std = 1.0\n",
        "kl_weight = 0.01\n",
        "num_sampled=24\n",
        "act = ELU()\n",
        "\n",
        "\n",
        "x = Input(shape=(max_len,))\n",
        "x_embed = Embedding(NB_WORDS, emb_dim, weights=[glove_embedding_matrix],\n",
        "                            input_length=max_len, trainable=False)(x)\n",
        "h = Bidirectional(LSTM(intermediate_dim, return_sequences=False, recurrent_dropout=0.2), merge_mode='concat')(x_embed)\n",
        "#h = Bidirectional(LSTM(intermediate_dim, return_sequences=False), merge_mode='concat')(h)\n",
        "#h = Dropout(0.2)(h)\n",
        "#h = Dense(intermediate_dim, activation='linear')(h)\n",
        "#h = act(h)\n",
        "#h = Dropout(0.2)(h)\n",
        "z_mean = Dense(latent_dim)(h)\n",
        "z_log_var = Dense(latent_dim)(h)\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n",
        "                              stddev=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
        "\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "# we instantiate these layers separately so as to reuse them later\n",
        "repeated_context = RepeatVector(max_len)\n",
        "decoder_h = LSTM(intermediate_dim, return_sequences=True, recurrent_dropout=0.2)\n",
        "decoder_mean = Dense(NB_WORDS, activation='linear')#softmax is applied in the seq2seqloss by tf #TimeDistributed()\n",
        "h_decoded = decoder_h(repeated_context(z))\n",
        "x_decoded_mean = decoder_mean(h_decoded)\n",
        "\n",
        "\n",
        "# placeholder loss\n",
        "def zero_loss(y_true, y_pred):\n",
        "    return K.zeros_like(y_pred)\n",
        "\n",
        "print('y')\n",
        "#Sampled softmax\n",
        "logits = tf.constant(np.random.randn(batch_size, max_len, NB_WORDS), tf.float32)\n",
        "targets = tf.constant(np.random.randint(NB_WORDS, size=(batch_size, max_len)), tf.int32)\n",
        "proj_w = tf.constant(np.random.randn(EMBEDDING_DIM, NB_WORDS), tf.float32)\n",
        "proj_b = tf.constant(np.zeros(NB_WORDS), tf.float32)\n",
        "print('x')\n",
        "\n",
        "def _sampled_loss(labels, logits):\n",
        "    labels = tf.cast(labels, tf.int64)\n",
        "    labels = tf.reshape(labels, [-1, 1])\n",
        "    logits = tf.cast(logits, tf.float32)\n",
        "    return tf.cast(\n",
        "                    tf.nn.sampled_softmax_loss(\n",
        "                        proj_w,\n",
        "                        proj_b,\n",
        "                        labels,\n",
        "                        logits,\n",
        "                        num_sampled=num_sampled,\n",
        "                        num_classes=NB_WORDS),\n",
        "                    tf.float32)\n",
        "softmax_loss_f = _sampled_loss\n",
        "\n",
        "\n",
        "# Custom loss layer\n",
        "class CustomVariationalLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.is_placeholder = True\n",
        "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
        "        self.target_weights = tf.constant(np.ones((batch_size, max_len)), tf.float32)\n",
        "\n",
        "    def vae_loss(self, x, x_decoded_mean):\n",
        "        #xent_loss = K.sum(metrics.categorical_crossentropy(x, x_decoded_mean), axis=-1)\n",
        "        labels = tf.cast(x, tf.int32)\n",
        "        xent_loss = K.sum(tf.contrib.seq2seq.sequence_loss(x_decoded_mean, labels, \n",
        "                                                     weights=self.target_weights,\n",
        "                                                     average_across_timesteps=False,\n",
        "                                                     average_across_batch=False,#), axis=-1)#,\n",
        "                                                     softmax_loss_function=softmax_loss_f), axis=-1)#,\n",
        "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "        xent_loss = K.mean(xent_loss)\n",
        "        kl_loss = K.mean(kl_loss)\n",
        "        return K.mean(xent_loss + kl_weight * kl_loss)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs[0]\n",
        "        x_decoded_mean = inputs[1]\n",
        "        print(x.shape, x_decoded_mean.shape)\n",
        "        loss = self.vae_loss(x, x_decoded_mean)\n",
        "        self.add_loss(loss, inputs=inputs)\n",
        "        # we don't use this output, but it has to have the correct shape:\n",
        "        return K.ones_like(x)\n",
        "    \n",
        "def kl_loss(x, x_decoded_mean):\n",
        "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "    kl_loss = kl_weight * kl_loss\n",
        "    return kl_loss\n",
        "\n",
        "loss_layer = CustomVariationalLayer()([x, x_decoded_mean])\n",
        "vae = Model(x, [loss_layer])\n",
        "opt = Adam(lr=0.005) \n",
        "opt = Nadam(lr=0.001) \n",
        "vae.compile(optimizer=opt, loss=[zero_loss], metrics=[kl_loss])\n",
        "vae.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y\n",
            "x\n",
            "(?, 20) (?, 20, 2001)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 20, 300)      600300      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 1024)         3330048     embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 128)          131200      bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 128)          131200      bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 128)          0           dense_7[0][0]                    \n",
            "                                                                 dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_3 (RepeatVector)  (None, 20, 128)      0           lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   (None, 20, 512)      1312768     repeat_vector_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 20, 2001)     1026513     lstm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "custom_variational_layer_3 (Cus [(None, 20), (None,  0           input_3[0][0]                    \n",
            "                                                                 dense_9[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 6,532,029\n",
            "Trainable params: 5,931,729\n",
            "Non-trainable params: 600,300\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sab66ujA3TFe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model training\n",
        "We train our model for 100 epochs through keras \".fit()\". For validation data we pass the same array twice since input and labels of this model are the same. If we didn't use the \"tf.contrib.seq2seq.sequence_loss\" (or another similar function) we would have had to pass as labels the sequence of word one-hot encodings with dimension (batch_size, seq_len, vocab_size) consuming a lot of memory."
      ]
    },
    {
      "metadata": {
        "id": "i42E_R0x3TFg",
        "colab_type": "code",
        "outputId": "c0e9736c-905f-494b-cbab-a278acee9950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "cell_type": "code",
      "source": [
        "def create_model_checkpoint(dir, model_name):\n",
        "    filepath = dir + '/' + model_name + \".h5\" \n",
        "    directory = os.path.dirname(filepath)\n",
        "    try:\n",
        "        os.stat(directory)\n",
        "    except:\n",
        "        os.mkdir(directory)\n",
        "    checkpointer = ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
        "    return checkpointer\n",
        "\n",
        "checkpointer = create_model_checkpoint(MODEL_DIR, 'vae_seq2seq_test_very_high_std')\n",
        "\n",
        "\n",
        "\n",
        "history = vae.fit(data_train, data_train,\n",
        "     shuffle=True,\n",
        "     epochs=max_epochs,\n",
        "     batch_size=batch_size,\n",
        "     verbose=2,\n",
        "     validation_data=(data_val, data_val), callbacks=[checkpointer])\n",
        "\n",
        "#print(K.eval(vae.optimizer.lr))\n",
        "#K.set_value(vae.optimizer.lr, 0.01)\n",
        "\n",
        "vae.save(MODEL_DIR + '/vae_lstm.h5')\n",
        "#vae.load_weights('models/vae_seq2seq_test.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 70000 samples, validate on 8000 samples\n",
            "Epoch 1/100\n",
            " - 142s - loss: 51.3716 - kl_loss: 1.0872 - val_loss: 38.2140 - val_kl_loss: 1.1813\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 38.21398, saving model to /content/gdrive/My Drive/Colab Notebooks/vae_seq2seq_test_very_high_std.h5\n",
            "Epoch 2/100\n",
            " - 137s - loss: 26.7506 - kl_loss: 1.2438 - val_loss: 24.7833 - val_kl_loss: 1.3165\n",
            "\n",
            "Epoch 00002: val_loss improved from 38.21398 to 24.78333, saving model to /content/gdrive/My Drive/Colab Notebooks/vae_seq2seq_test_very_high_std.h5\n",
            "Epoch 3/100\n",
            " - 137s - loss: 23.6589 - kl_loss: 1.3237 - val_loss: 23.1875 - val_kl_loss: 1.4181\n",
            "\n",
            "Epoch 00003: val_loss improved from 24.78333 to 23.18754, saving model to /content/gdrive/My Drive/Colab Notebooks/vae_seq2seq_test_very_high_std.h5\n",
            "Epoch 4/100\n",
            " - 137s - loss: 38.3874 - kl_loss: 1.2906 - val_loss: 47.2712 - val_kl_loss: 0.7300\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 23.18754\n",
            "Epoch 5/100\n",
            " - 138s - loss: 38.1599 - kl_loss: 0.9397 - val_loss: 28.7222 - val_kl_loss: 1.4463\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 23.18754\n",
            "Epoch 6/100\n",
            " - 137s - loss: 23.4664 - kl_loss: 1.4666 - val_loss: 22.1544 - val_kl_loss: 1.4830\n",
            "\n",
            "Epoch 00006: val_loss improved from 23.18754 to 22.15442, saving model to /content/gdrive/My Drive/Colab Notebooks/vae_seq2seq_test_very_high_std.h5\n",
            "Epoch 7/100\n",
            " - 138s - loss: 21.2091 - kl_loss: 1.4624 - val_loss: 21.2363 - val_kl_loss: 1.4899\n",
            "\n",
            "Epoch 00007: val_loss improved from 22.15442 to 21.23629, saving model to /content/gdrive/My Drive/Colab Notebooks/vae_seq2seq_test_very_high_std.h5\n",
            "Epoch 8/100\n",
            " - 138s - loss: 20.4168 - kl_loss: 1.4584 - val_loss: 19.9156 - val_kl_loss: 1.4916\n",
            "\n",
            "Epoch 00008: val_loss improved from 21.23629 to 19.91556, saving model to /content/gdrive/My Drive/Colab Notebooks/vae_seq2seq_test_very_high_std.h5\n",
            "Epoch 9/100\n",
            " - 138s - loss: 19.6165 - kl_loss: 1.4457 - val_loss: 19.4192 - val_kl_loss: 1.4825\n",
            "\n",
            "Epoch 00009: val_loss improved from 19.91556 to 19.41924, saving model to /content/gdrive/My Drive/Colab Notebooks/vae_seq2seq_test_very_high_std.h5\n",
            "Epoch 10/100\n",
            " - 138s - loss: 19.1238 - kl_loss: 1.4366 - val_loss: 18.9278 - val_kl_loss: 1.4890\n",
            "\n",
            "Epoch 00010: val_loss improved from 19.41924 to 18.92784, saving model to /content/gdrive/My Drive/Colab Notebooks/vae_seq2seq_test_very_high_std.h5\n",
            "Epoch 11/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oyoR20RWcYll",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -sh models/vae_seq2seq_test_very_high_std.h5\n",
        "!ls -sh models/vae_lstm.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-6vaE7m6NIvu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if history != None:\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['kl_loss'])\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_kl_loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model val loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['kl_loss', 'loss'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Aa__Ihl3TFy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Project and sample sentences from the latent space\n",
        "Now we build an encoder model model that takes a sentence and projects it on the latent space and a decoder model that goes from the latent space back to the text representation"
      ]
    },
    {
      "metadata": {
        "id": "Qu7p1AU13TF1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build a model to project inputs on the latent space\n",
        "encoder = Model(x, z_mean)\n",
        "#encoder.save('models/encoder32dim512hid30kvocab_loss29_val34.h5')\n",
        "\n",
        "# build a generator that can sample from the learned distribution\n",
        "decoder_input = Input(shape=(latent_dim,))\n",
        "_h_decoded = decoder_h(repeated_context(decoder_input))\n",
        "_x_decoded_mean = decoder_mean(_h_decoded)\n",
        "_x_decoded_mean = Activation('softmax')(_x_decoded_mean)\n",
        "generator = Model(decoder_input, _x_decoded_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XZMYjrGX3TGU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test on validation sentences"
      ]
    },
    {
      "metadata": {
        "id": "155bV8293TG6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index2word = {v: k for k, v in word_index.items()}\n",
        "index2word[0] = 'pad'\n",
        "\n",
        "#test on a validation sentence\n",
        "sent_idx = 100\n",
        "sent_encoded = encoder.predict(data_val[sent_idx:sent_idx+2,:])\n",
        "x_test_reconstructed = generator.predict(sent_encoded, batch_size = 1)\n",
        "reconstructed_indexes = np.apply_along_axis(np.argmax, 1, x_test_reconstructed[0])\n",
        "#np.apply_along_axis(np.max, 1, x_test_reconstructed[0])\n",
        "#np.max(np.apply_along_axis(np.max, 1, x_test_reconstructed[0]))\n",
        "word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
        "print(' '.join(word_list))\n",
        "original_sent = list(np.vectorize(index2word.get)(data_val[sent_idx]))\n",
        "print(' '.join(original_sent))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pat8y0Cw3TG_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sentence processing and interpolation"
      ]
    },
    {
      "metadata": {
        "id": "vw0dajiS3THF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function to parse a sentence\n",
        "def sent_parse(sentence, mat_shape):\n",
        "    sequence = tokenizer.texts_to_sequences(sentence)\n",
        "    padded_sent = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    return padded_sent#[padded_sent, sent_one_hot]\n",
        "\n",
        "# input: encoded sentence vector\n",
        "# output: encoded sentence vector in dataset with highest cosine similarity\n",
        "def find_similar_encoding(sent_vect):\n",
        "    all_cosine = []\n",
        "    for sent in sent_encoded:\n",
        "        result = 1 - spatial.distance.cosine(sent_vect, sent)\n",
        "        all_cosine.append(result)\n",
        "    data_array = np.array(all_cosine)\n",
        "    maximum = data_array.argsort()[-3:][::-1][1]\n",
        "    new_vec = sent_encoded[maximum]\n",
        "    return new_vec\n",
        "\n",
        "# input: two points, integer n\n",
        "# output: n equidistant points on the line between the input points (inclusive)\n",
        "def shortest_homology(point_one, point_two, num):\n",
        "    dist_vec = point_two - point_one\n",
        "    sample = np.linspace(0, 1, num, endpoint = True)\n",
        "    hom_sample = []\n",
        "    for s in sample:\n",
        "        hom_sample.append(point_one + s * dist_vec)\n",
        "    return hom_sample\n",
        "\n",
        "# input: original dimension sentence vector\n",
        "# output: sentence text\n",
        "def print_latent_sentence(sent_vect):\n",
        "    sent_vect = np.reshape(sent_vect,[1,latent_dim])\n",
        "    sent_reconstructed = generator.predict(sent_vect)\n",
        "    sent_reconstructed = np.reshape(sent_reconstructed,[max_len,NB_WORDS])\n",
        "    reconstructed_indexes = np.apply_along_axis(np.argmax, 1, sent_reconstructed)\n",
        "    word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
        "    w_list = [w for w in word_list if w not in ['pad']]\n",
        "    print(' '.join(w_list))\n",
        "    #print(word_list)\n",
        "     \n",
        "def new_sents_interp(sent1, sent2, n):\n",
        "    tok_sent1 = sent_parse(sent1, [MAX_SEQUENCE_LENGTH + 2])\n",
        "    tok_sent2 = sent_parse(sent2, [MAX_SEQUENCE_LENGTH + 2])\n",
        "    enc_sent1 = encoder.predict(tok_sent1, batch_size = 16)\n",
        "    enc_sent2 = encoder.predict(tok_sent2, batch_size = 16)\n",
        "    test_hom = shortest_homology(enc_sent1, enc_sent2, n)\n",
        "    for point in test_hom:\n",
        "        print_latent_sentence(point)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PWp9LWBd3THT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Example\n",
        "Now we can try to parse two sentences and interpolate between them generating new sentences"
      ]
    },
    {
      "metadata": {
        "id": "H6vKlFw93THU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence1=['gogogo a woman on a bicyle endend']\n",
        "mysent = sent_parse(sentence1, [MAX_SEQUENCE_LENGTH + 2])\n",
        "mysent_encoded = encoder.predict(mysent, batch_size = 16)\n",
        "print_latent_sentence(mysent_encoded)\n",
        "print_latent_sentence(find_similar_encoding(mysent_encoded))\n",
        "\n",
        "sentence2=['gogogo many people running towards a stop sign endend']\n",
        "mysent2 = sent_parse(sentence2, [MAX_SEQUENCE_LENGTH + 2])\n",
        "mysent_encoded2 = encoder.predict(mysent2, batch_size = 16)\n",
        "print_latent_sentence(mysent_encoded2)\n",
        "print_latent_sentence(find_similar_encoding(mysent_encoded2))\n",
        "print('-----------------')\n",
        "\n",
        "new_sents_interp(sentence1, sentence2, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UQGlH2xy3THa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Results\n",
        "TO UPDATE\n",
        "\n",
        "Results are not yet completely satisfying because not all the sentences are grammatically correct and in the interpolation the same sentence has been generated multiple times but anyway the model, even in this preliminary version seems to start working.\n",
        "There are certainly many improvements that could be done like:\n",
        "-  parameter tuning (this model trains in few hours on a GTX950M with 2GB memory so it's definitely possible to try larger nets)\n",
        "-  train on a more general dataset (Quora sentences are all questions)"
      ]
    }
  ]
}